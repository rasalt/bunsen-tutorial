{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> HIMSS Demo - HealtheDatalab </h1>\n",
    "\n",
    "<h2> Structured Machine Learning using Tensorflow </h2>\n",
    "<hr />\n",
    "This notebook demonstrates a process to train, evaluate and deploy a ML model to CloudML. It leverages a pre-built machine learning model to predict Length of Stay in ED and inpatient care settings\n",
    "<h3>\n",
    "<br />\n",
    "<ol>\n",
    "<li> Access, Analize & Visualize Data using HealtheDataLab </li> <br />\n",
    "<li> Label generation - Generate Labels in TFRecord format </li> <br />\n",
    "<li> Generate TFSequenceExamples with context = patient + time series data = encounters </li> <br />\n",
    "<li> Train and Evaluate Machine Learning Model </li> <br />\n",
    "<li> Deploy ML Model to CloudML </li> <br />\n",
    "</ol>\n",
    "</h3>\n",
    "<hr />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "#python demo_utils.py\n",
    "#import demo_utils\n",
    "#print(demo_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Access, Analize & Visualize Data using HealtheDataLab </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>male</td>\n",
       "      <td>1980-11-07</td>\n",
       "      <td>[Pittsfield]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:345efce8-d11d-429d-9984-6b67e31a7269</td>\n",
       "      <td>male</td>\n",
       "      <td>1952-06-04</td>\n",
       "      <td>[Harwich]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:44810270-bafe-42a4-8fc8-c229368b0058</td>\n",
       "      <td>male</td>\n",
       "      <td>1966-02-17</td>\n",
       "      <td>[Hubbardston]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:d6be5e17-7733-4096-b3a7-32c2a80582af</td>\n",
       "      <td>female</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>[Worcester]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:5c6ad3ff-99b1-47b3-92c1-a37d82a5a559</td>\n",
       "      <td>male</td>\n",
       "      <td>1961-03-13</td>\n",
       "      <td>[Methuen Town]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:e3952c11-3fa2-4492-899c-bbbb8c7b6db0</td>\n",
       "      <td>male</td>\n",
       "      <td>1956-07-01</td>\n",
       "      <td>[Wareham]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:665b7d87-1e8a-46f5-a2fb-6e8200f6662e</td>\n",
       "      <td>male</td>\n",
       "      <td>1952-08-05</td>\n",
       "      <td>[Hudson]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:08e56bf9-7034-4b6e-8345-c61a0d910c6e</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-03-29</td>\n",
       "      <td>[Brockton]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:e272d8a3-73c9-4887-a457-f0d1d7cc1e44</td>\n",
       "      <td>female</td>\n",
       "      <td>2003-11-19</td>\n",
       "      <td>[Weymouth Town]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:1d9e528b-18b4-4cfa-bfd4-d2eb85e9ce1b</td>\n",
       "      <td>female</td>\n",
       "      <td>1984-11-14</td>\n",
       "      <td>[Lowell]</td>\n",
       "      <td>[Massachusetts]</td>\n",
       "      <td>[US]</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  gender   birthDate  \\\n",
       "0  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354    male  1980-11-07   \n",
       "1  urn:uuid:345efce8-d11d-429d-9984-6b67e31a7269    male  1952-06-04   \n",
       "2  urn:uuid:44810270-bafe-42a4-8fc8-c229368b0058    male  1966-02-17   \n",
       "3  urn:uuid:d6be5e17-7733-4096-b3a7-32c2a80582af  female  2018-12-29   \n",
       "4  urn:uuid:5c6ad3ff-99b1-47b3-92c1-a37d82a5a559    male  1961-03-13   \n",
       "5  urn:uuid:e3952c11-3fa2-4492-899c-bbbb8c7b6db0    male  1956-07-01   \n",
       "6  urn:uuid:665b7d87-1e8a-46f5-a2fb-6e8200f6662e    male  1952-08-05   \n",
       "7  urn:uuid:08e56bf9-7034-4b6e-8345-c61a0d910c6e  female  1963-03-29   \n",
       "8  urn:uuid:e272d8a3-73c9-4887-a457-f0d1d7cc1e44  female  2003-11-19   \n",
       "9  urn:uuid:1d9e528b-18b4-4cfa-bfd4-d2eb85e9ce1b  female  1984-11-14   \n",
       "\n",
       "              city            state country age  \n",
       "0     [Pittsfield]  [Massachusetts]    [US]  38  \n",
       "1        [Harwich]  [Massachusetts]    [US]  66  \n",
       "2    [Hubbardston]  [Massachusetts]    [US]  52  \n",
       "3      [Worcester]  [Massachusetts]    [US]   0  \n",
       "4   [Methuen Town]  [Massachusetts]    [US]  57  \n",
       "5        [Wareham]  [Massachusetts]    [US]  62  \n",
       "6         [Hudson]  [Massachusetts]    [US]  66  \n",
       "7       [Brockton]  [Massachusetts]    [US]  55  \n",
       "8  [Weymouth Town]  [Massachusetts]    [US]  15  \n",
       "9         [Lowell]  [Massachusetts]    [US]  34  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from bunsen.stu3.bundles import load_from_directory, extract_entry\n",
    "from demo_utils import age\n",
    "\n",
    "# Enable Hive support for our session so we can save resources as Hive tables\n",
    "spark = SparkSession.builder \\\n",
    "                    .config('hive.exec.dynamic.partition.mode', 'nonstrict') \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "# Load and cache the bundles so we don't reload them every time.\n",
    "bundles = load_from_directory(spark, 'gs://cluster-data/demo/data/synthea/fhir/').cache()\n",
    "\n",
    "# Extract patients from bundles\n",
    "patients = extract_entry(spark, bundles, 'patient')\n",
    "\n",
    "pats = patients.select('id','gender', 'birthDate', 'address.city', 'address.state', 'address.country') \n",
    "\n",
    "#pats['birthDate'] = pats['birthDate'].apply(age)\n",
    "patsDF = pats.limit(10).toPandas()\n",
    "patsDF['age'] = patsDF['birthDate'].apply(age)\n",
    "display(patsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>code</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1994-12-11T11:05:54-08:00</td>\n",
       "      <td>1994-12-12T11:20:54-08:00</td>\n",
       "      <td>1 day, 0:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1995-04-06T12:05:54-07:00</td>\n",
       "      <td>1995-04-07T12:20:54-07:00</td>\n",
       "      <td>1 day, 0:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1995-06-19T12:05:54-07:00</td>\n",
       "      <td>1995-06-20T12:05:54-07:00</td>\n",
       "      <td>1 day, 0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1995-08-25T12:05:54-07:00</td>\n",
       "      <td>1995-08-26T12:05:54-07:00</td>\n",
       "      <td>1 day, 0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1995-11-28T11:05:54-08:00</td>\n",
       "      <td>1995-11-29T11:05:54-08:00</td>\n",
       "      <td>1 day, 0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1996-01-18T11:05:54-08:00</td>\n",
       "      <td>1996-01-19T11:05:54-08:00</td>\n",
       "      <td>1 day, 0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1996-03-02T11:05:54-08:00</td>\n",
       "      <td>1996-03-03T11:20:54-08:00</td>\n",
       "      <td>1 day, 0:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1996-04-22T12:05:54-07:00</td>\n",
       "      <td>1996-04-23T12:20:54-07:00</td>\n",
       "      <td>1 day, 0:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1996-10-01T12:05:54-07:00</td>\n",
       "      <td>1996-10-02T12:05:54-07:00</td>\n",
       "      <td>1 day, 0:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:c127185e-9f14-462a-9817-c90963fb7354</td>\n",
       "      <td>inpatient</td>\n",
       "      <td>1996-12-17T11:05:54-08:00</td>\n",
       "      <td>1996-12-18T11:20:54-08:00</td>\n",
       "      <td>1 day, 0:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reference       code  \\\n",
       "0  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "1  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "2  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "3  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "4  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "5  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "6  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "7  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "8  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "9  urn:uuid:c127185e-9f14-462a-9817-c90963fb7354  inpatient   \n",
       "\n",
       "                       start                        end             los  \n",
       "0  1994-12-11T11:05:54-08:00  1994-12-12T11:20:54-08:00  1 day, 0:15:00  \n",
       "1  1995-04-06T12:05:54-07:00  1995-04-07T12:20:54-07:00  1 day, 0:15:00  \n",
       "2  1995-06-19T12:05:54-07:00  1995-06-20T12:05:54-07:00  1 day, 0:00:00  \n",
       "3  1995-08-25T12:05:54-07:00  1995-08-26T12:05:54-07:00  1 day, 0:00:00  \n",
       "4  1995-11-28T11:05:54-08:00  1995-11-29T11:05:54-08:00  1 day, 0:00:00  \n",
       "5  1996-01-18T11:05:54-08:00  1996-01-19T11:05:54-08:00  1 day, 0:00:00  \n",
       "6  1996-03-02T11:05:54-08:00  1996-03-03T11:20:54-08:00  1 day, 0:15:00  \n",
       "7  1996-04-22T12:05:54-07:00  1996-04-23T12:20:54-07:00  1 day, 0:15:00  \n",
       "8  1996-10-01T12:05:54-07:00  1996-10-02T12:05:54-07:00  1 day, 0:00:00  \n",
       "9  1996-12-17T11:05:54-08:00  1996-12-18T11:20:54-08:00  1 day, 0:15:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from demo_utils import los\n",
    "\n",
    "# Extract encounters from bundles\n",
    "encounters = extract_entry(spark, bundles, 'encounter') \n",
    "\n",
    "encs=encounters.select('subject.reference', \n",
    "                  'class.code', \n",
    "                  'period.start', \n",
    "                  'period.end') \\\n",
    "          .where(col('class.code').isin(\"inpatient\", \"emergency\"))\n",
    "\n",
    "\n",
    "encsDF = encs.limit(10).toPandas()\n",
    "encsDF['los'] = encsDF.apply(los, axis=1)\n",
    "display(encsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE(WIP)\n",
    "PROJECT = 'dp-workspace'\n",
    "REGION = 'us-west1'\n",
    "BUCKET = 'cluster-data'\n",
    "\n",
    "import os\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Preparation of data - Create input data bundles in TFRecord format</h2>\n",
    "This cell creates FHIR bundles from RAW Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Enable Hive support for our session so we can save resources as Hive tables\n",
    "spark = SparkSession.builder \\\n",
    "                    .config('hive.exec.dynamic.partition.mode', 'nonstrict') \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "from bunsen.stu3.bundles import load_from_directory, extract_entry, write_to_database\n",
    "\n",
    "# Load and cache the raw data (FHIR bundles) from Google Cloud Storage bucket so we don't reload them every time.\n",
    "bundles = load_from_directory(spark, 'gs://bunsen/data/bundles').cache()\n",
    "\n",
    "# Create TFRecords from the raw FHIR bundles (one line to create TFrecordas)\n",
    "#TODO ........\n",
    "#For now we have generated a sample TF Record and stored in a following cloud storage bucket: gs://cluster-data/demo/data/test_bundle.tfrecord-00000-of-00001 \n",
    "#Text version of the test_bundle.tfrecord-00000-of-00001 is in file: bundle_1.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls -l gs://${BUCKET}/demo/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3. Label generation - Generate Labels in TFRecord format</h2>\n",
    "Input: FHIR bundles\n",
    "Output: Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app\n",
    "from absl import flags\n",
    "import apache_beam as beam\n",
    "from proto.stu3 import google_extensions_pb2\n",
    "from proto.stu3 import resources_pb2\n",
    "from py.google.fhir.labels import encounter\n",
    "from py.google.fhir.labels import label\n",
    "\n",
    "@beam.typehints.with_input_types(resources_pb2.Bundle)\n",
    "@beam.typehints.with_output_types(google_extensions_pb2.EventLabel)\n",
    "class LengthOfStayRangeLabelAt24HoursFn(beam.DoFn):\n",
    "  \"\"\"Converts Bundle into length of stay range at 24 hours label.\n",
    "\n",
    "    Cohort: inpatient encounter that is longer than 24 hours\n",
    "    Trigger point: 24 hours after admission\n",
    "    Label: multi-label for length of stay ranges, see label.py for detail\n",
    "  \"\"\"\n",
    "\n",
    "  def process(self, bundle):\n",
    "    \"\"\"Iterate through bundle and yield label.\n",
    "\n",
    "    Args:\n",
    "      bundle: input stu3.Bundle proto\n",
    "    Yields:\n",
    "      stu3.EventLabel proto.\n",
    "    \"\"\"\n",
    "    patient = encounter.GetPatient(bundle)\n",
    "    if patient is not None:\n",
    "      # Cohort: inpatient encounter > 24 hours.\n",
    "      for enc in encounter.Inpatient24HrEncounters(bundle):\n",
    "        for one_label in label.LengthOfStayRangeAt24Hours(patient, enc):\n",
    "          yield one_label\n",
    "          \n",
    "          \n",
    "          \n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.metrics.metric import MetricsFilter\n",
    "\n",
    "import apache_beam as beam\n",
    "import re\n",
    "\n",
    "\n",
    "options = PipelineOptions()\n",
    "google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "#google_cloud_options.project = 'dp-workspace'\n",
    "google_cloud_options.project = PROJECT\n",
    "google_cloud_options.job_name = 'job1'\n",
    "google_cloud_options.staging_location = 'gs://cluster-data/demo/staging'\n",
    "google_cloud_options.temp_location = 'gs://cluster-data/demo/temp'\n",
    "options.view_as(StandardOptions).runner = 'DirectRunner'\n",
    "\n",
    "p = beam.Pipeline(options=options)\n",
    "input_bundle = 'gs://cluster-data/demo/data/test_bundle.tfrecord-00000-of-00001'\n",
    "output_file_prefix = 'gs://cluster-data/demo/data/output/label'\n",
    "\n",
    "bundles = p | 'read' >> beam.io.ReadFromTFRecord(input_bundle, coder=beam.coders.ProtoCoder(resources_pb2.Bundle))\n",
    "    \n",
    "labels = bundles | 'BundleToLabel' >> beam.ParDo(\n",
    "    LengthOfStayRangeLabelAt24HoursFn())\n",
    "_ = labels | beam.io.WriteToTFRecord(output_file_prefix,\n",
    "    coder=beam.coders.ProtoCoder(google_extensions_pb2.EventLabel))\n",
    "\n",
    "\n",
    "p.run().wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above cell generates a label TFRecord and stores it into a GS Bucket\n",
    "%bash\n",
    "gsutil ls -l gs://cluster-data/demo/data/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Generate TFSequenceExamples with context = patient + time series data = encounters</h2>\n",
    "Input: FHIR bundles\n",
    "Output: Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE(WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Train and Evaluate Machine Learning Model </h2>\n",
    "Input: Training and Evaluation Dataset\n",
    "Output: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE(WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6. Deploy ML Model to ??? </h2>\n",
    "Input: New Data set\n",
    "Output: Length Of Stay Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE(WIP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
