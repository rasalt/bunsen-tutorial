{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates bundles to seqex example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages required for apache-beam and protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/ipykernel/__main__.py:12: ImportWarning: Not importing directory '/usr/local/fhir/proto': missing __init__.py\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import apache_beam as beam\n",
    "from google.protobuf import text_format\n",
    "from proto.stu3 import google_extensions_pb2\n",
    "from proto.stu3 import resources_pb2\n",
    "from proto.stu3 import version_config_pb2\n",
    "from tensorflow.core.example import example_pb2\n",
    "from py.google.fhir.seqex import bundle_to_seqex\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_version_config(version_config_path):\n",
    "  with open(version_config_path) as f:\n",
    "    return text_format.Parse(f.read(), version_config_pb2.VersionConfig())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.metrics.metric import MetricsFilter\n",
    "\n",
    "import apache_beam as beam\n",
    "import re\n",
    "\n",
    "options = PipelineOptions()\n",
    "google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "google_cloud_options.project = 'dp-workspace'\n",
    "google_cloud_options.job_name = 'generate_seqex'\n",
    "google_cloud_options.staging_location = 'gs://cluster-data/staging'\n",
    "google_cloud_options.temp_location = 'gs://cluster-data/temp'\n",
    "options.view_as(StandardOptions).runner = 'DirectRunner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'gs://cluster-data/demo/data/bundles/bundles*'\n",
    "label_path = 'gs://cluster-data/demo/data/output/labels-00000-of-00001.tfrecords'\n",
    "output_path = 'gs://cluster-data/demo/data/output/seqex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/oauth2client/contrib/gce.py:99: UserWarning: You have requested explicit scopes to be used with a GCE service account.\n",
      "Using this argument will have no effect on the actual scopes for tokens\n",
      "requested. These scopes are set at VM instance creation time and\n",
      "can't be overridden in the request.\n",
      "\n",
      "  warnings.warn(_SCOPES_WARNING)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0124 19:58:37.658966 140304687015680 gcsio.py:446] Starting the size estimation of the input\n",
      "I0124 19:58:37.662934 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:58:37.783057 140304687015680 gcsio.py:460] Finished listing 10 files in 0.12409901619 seconds.\n",
      "I0124 19:58:37.802076 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:58:37.871395 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n"
     ]
    }
   ],
   "source": [
    "p = beam.Pipeline(options=options)\n",
    "version_config = _get_version_config(\"/usr/local/fhir/proto/stu3/version_config.textproto\")\n",
    "\n",
    "keyed_bundles = ( \n",
    "    p \n",
    "    | 'readBundles' >> beam.io.ReadFromTFRecord(\n",
    "        input_path, coder=beam.coders.ProtoCoder(resources_pb2.Bundle))\n",
    "    | 'KeyBundlesByPatientId' >> beam.ParDo(\n",
    "        bundle_to_seqex.KeyBundleByPatientIdFn()))\n",
    "event_labels = ( \n",
    "    p | 'readEventLabels' >> beam.io.ReadFromTFRecord(\n",
    "        label_path,\n",
    "        coder=beam.coders.ProtoCoder(google_extensions_pb2.EventLabel)))\n",
    "keyed_event_labels = bundle_to_seqex.CreateTriggerLabelsPairLists(\n",
    "    event_labels)\n",
    "bundles_and_labels = bundle_to_seqex.CreateBundleAndLabels(\n",
    "    keyed_bundles, keyed_event_labels)\n",
    "_ = ( \n",
    "    bundles_and_labels\n",
    "    | 'Reshuffle1' >> beam.Reshuffle()\n",
    "    | 'GenerateSeqex' >> beam.ParDo(\n",
    "        bundle_to_seqex.BundleAndLabelsToSeqexDoFn(\n",
    "            version_config=version_config,\n",
    "            enable_attribution=False,\n",
    "            generate_sequence_label=False))\n",
    "    | 'Reshuffle2' >> beam.Reshuffle()\n",
    "    | 'WriteSeqex' >> beam.io.WriteToTFRecord(\n",
    "        output_path,\n",
    "        coder=beam.coders.ProtoCoder(example_pb2.SequenceExample),\n",
    "        file_name_suffix='.tfrecords',\n",
    "        num_shards=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0124 19:58:46.944423 140304687015680 fn_api_runner.py:844] ==================== <function annotate_downstream_side_inputs at 0x7f9ae90785f0> ====================\n",
      "I0124 19:58:46.947788 140304687015680 fn_api_runner.py:844] ==================== <function fix_side_input_pcoll_coders at 0x7f9ae9078668> ====================\n",
      "I0124 19:58:46.952614 140304687015680 fn_api_runner.py:844] ==================== <function lift_combiners at 0x7f9ae9078488> ====================\n",
      "I0124 19:58:46.954586 140304687015680 fn_api_runner.py:844] ==================== <function expand_gbk at 0x7f9ae9078500> ====================\n",
      "I0124 19:58:46.962486 140304687015680 fn_api_runner.py:844] ==================== <function sink_flattens at 0x7f9ae9078578> ====================\n",
      "I0124 19:58:46.965171 140304687015680 fn_api_runner.py:844] ==================== <function greedily_fuse at 0x7f9ae90786e0> ====================\n",
      "I0124 19:58:46.970021 140304687015680 fn_api_runner.py:844] ==================== <function sort_stages at 0x7f9ae9078758> ====================\n",
      "I0124 19:58:46.972425 140304687015680 fn_api_runner.py:912] Running ((ref_AppliedPTransform_WriteSeqex/Write/WriteImpl/DoOnce/Read_48)+((ref_AppliedPTransform_WriteSeqex/Write/WriteImpl/InitializeWrite_49)+(ref_PCollection_PCollection_33/Write)))+(ref_PCollection_PCollection_32/Write)\n",
      "I0124 19:58:46.984545 140304687015680 bundle_processor.py:291] start <DataOutputOperation ref_PCollection_PCollection_32/Write >\n",
      "I0124 19:58:46.987873 140304687015680 bundle_processor.py:291] start <DataOutputOperation ref_PCollection_PCollection_33/Write >\n",
      "I0124 19:58:46.989535 140304687015680 bundle_processor.py:291] start <DoOperation WriteSeqex/Write/WriteImpl/InitializeWrite output_tags=['out']>\n",
      "I0124 19:58:46.993908 140304687015680 bundle_processor.py:291] start <ReadOperation WriteSeqex/Write/WriteImpl/DoOnce/Read source=SourceBundle(weight=1.0, source=<apache_beam.transforms.create_source._CreateSource object at 0x7f9ae8b49550>, start_position=None, stop_position=None)>\n",
      "I0124 19:58:46.998186 140304687015680 bundle_processor.py:303] finish <ReadOperation WriteSeqex/Write/WriteImpl/DoOnce/Read source=SourceBundle(weight=1.0, source=<apache_beam.transforms.create_source._CreateSource object at 0x7f9ae8b49550>, start_position=None, stop_position=None), receivers=[ConsumerSet[WriteSeqex/Write/WriteImpl/DoOnce/Read.out0, coder=WindowedValueCoder[FastPrimitivesCoder], len(consumers)=2]]>\n",
      "I0124 19:58:46.999748 140304687015680 bundle_processor.py:303] finish <DoOperation WriteSeqex/Write/WriteImpl/InitializeWrite output_tags=['out'], receivers=[ConsumerSet[WriteSeqex/Write/WriteImpl/InitializeWrite.out0, coder=WindowedValueCoder[LengthPrefixCoder[FastPrimitivesCoder]], len(consumers)=1]]>\n",
      "I0124 19:58:47.001799 140304687015680 bundle_processor.py:303] finish <DataOutputOperation ref_PCollection_PCollection_33/Write >\n",
      "I0124 19:58:47.004513 140304687015680 bundle_processor.py:303] finish <DataOutputOperation ref_PCollection_PCollection_32/Write >\n",
      "I0124 19:58:47.013691 140304687015680 fn_api_runner.py:912] Running (((ref_AppliedPTransform_readBundles/Read_3)+((ref_AppliedPTransform_KeyBundlesByPatientId_4)+(ref_AppliedPTransform_GroupBundleAndTriggers/pair_with_bundle_15)))+(GroupBundleAndTriggers/Flatten/Transcode/1))+(GroupBundleAndTriggers/Flatten/Write/1)\n",
      "I0124 19:58:47.025290 140304687015680 bundle_processor.py:291] start <DataOutputOperation GroupBundleAndTriggers/Flatten/Write/1 >\n",
      "I0124 19:58:47.026896 140304687015680 bundle_processor.py:291] start <FlattenOperation GroupBundleAndTriggers/Flatten/Transcode/1 >\n",
      "I0124 19:58:47.029278 140304687015680 bundle_processor.py:291] start <DoOperation GroupBundleAndTriggers/pair_with_bundle output_tags=['out']>\n",
      "I0124 19:58:47.033575 140304687015680 bundle_processor.py:291] start <DoOperation KeyBundlesByPatientId output_tags=['out']>\n",
      "I0124 19:58:47.036350 140304687015680 bundle_processor.py:291] start <ReadOperation readBundles/Read source=SourceBundle(weight=1.0, source=<apache_beam.io.tfrecordio._TFRecordSource object at 0x7f9ae9172e10>, start_position=None, stop_position=None)>\n",
      "I0124 19:58:47.041745 140304687015680 gcsio.py:446] Starting the size estimation of the input\n",
      "I0124 19:58:47.044042 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:58:47.158687 140304687015680 gcsio.py:460] Finished listing 10 files in 0.11691904068 seconds.\n",
      "I0124 19:58:47.167772 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "W0124 19:58:47.481945 140304687015680 tfrecordio.py:49] Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "I0124 19:58:52.755059 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:58:59.866878 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:03.528606 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:07.128117 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:11.535933 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:15.570781 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:20.091670 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:24.811796 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:28.490756 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:32.068664 140304687015680 bundle_processor.py:303] finish <ReadOperation readBundles/Read source=SourceBundle(weight=1.0, source=<apache_beam.io.tfrecordio._TFRecordSource object at 0x7f9ae9172e10>, start_position=None, stop_position=None), receivers=[ConsumerSet[readBundles/Read.out0, coder=WindowedValueCoder[FastPrimitivesCoder], len(consumers)=1]]>\n",
      "I0124 19:59:32.071541 140304687015680 bundle_processor.py:303] finish <DoOperation KeyBundlesByPatientId output_tags=['out'], receivers=[ConsumerSet[KeyBundlesByPatientId.out0, coder=WindowedValueCoder[TupleCoder[BytesCoder, ProtoCoder]], len(consumers)=1]]>\n",
      "I0124 19:59:32.073955 140304687015680 bundle_processor.py:303] finish <DoOperation GroupBundleAndTriggers/pair_with_bundle output_tags=['out'], receivers=[ConsumerSet[GroupBundleAndTriggers/pair_with_bundle.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 19:59:32.076148 140304687015680 bundle_processor.py:303] finish <FlattenOperation GroupBundleAndTriggers/Flatten/Transcode/1 receivers=[ConsumerSet[GroupBundleAndTriggers/Flatten/Transcode/1.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 19:59:32.077824 140304687015680 bundle_processor.py:303] finish <DataOutputOperation GroupBundleAndTriggers/Flatten/Write/1 >\n",
      "I0124 19:59:35.796425 140304687015680 fn_api_runner.py:912] Running (ref_AppliedPTransform_readEventLabels/Read_6)+((ref_AppliedPTransform_KeyEventLabelsByPatientId_7)+(GroupEventLabelsByPatientId/Write))\n",
      "I0124 19:59:35.806145 140304687015680 bundle_processor.py:291] start <DataOutputOperation GroupEventLabelsByPatientId/Write >\n",
      "I0124 19:59:35.807702 140304687015680 bundle_processor.py:291] start <DoOperation KeyEventLabelsByPatientId output_tags=['out']>\n",
      "I0124 19:59:35.811270 140304687015680 bundle_processor.py:291] start <ReadOperation readEventLabels/Read source=SourceBundle(weight=1.0, source=<apache_beam.io.tfrecordio._TFRecordSource object at 0x7f9b02ec5a50>, start_position=None, stop_position=None)>\n",
      "I0124 19:59:35.816349 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:35.890889 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:35.956615 140304687015680 client.py:614] Attempting refresh to obtain initial access_token\n",
      "I0124 19:59:36.103636 140304687015680 bundle_processor.py:303] finish <ReadOperation readEventLabels/Read source=SourceBundle(weight=1.0, source=<apache_beam.io.tfrecordio._TFRecordSource object at 0x7f9b02ec5a50>, start_position=None, stop_position=None), receivers=[ConsumerSet[readEventLabels/Read.out0, coder=WindowedValueCoder[FastPrimitivesCoder], len(consumers)=1]]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0124 19:59:36.106637 140304687015680 bundle_processor.py:303] finish <DoOperation KeyEventLabelsByPatientId output_tags=['out'], receivers=[ConsumerSet[KeyEventLabelsByPatientId.out0, coder=WindowedValueCoder[TupleCoder[BytesCoder, LengthPrefixCoder[ProtoCoder]]], len(consumers)=1]]>\n",
      "I0124 19:59:36.108788 140304687015680 bundle_processor.py:303] finish <DataOutputOperation GroupEventLabelsByPatientId/Write >\n",
      "I0124 19:59:36.121429 140304687015680 fn_api_runner.py:912] Running (((GroupEventLabelsByPatientId/Read)+(ref_AppliedPTransform_CreateTriggerLabelsPairLists_12))+((ref_AppliedPTransform_GroupBundleAndTriggers/pair_with_trigger_labels_pair_lists_14)+(GroupBundleAndTriggers/Flatten/Transcode/0)))+(GroupBundleAndTriggers/Flatten/Write/0)\n",
      "I0124 19:59:36.136590 140304687015680 bundle_processor.py:291] start <DataOutputOperation GroupBundleAndTriggers/Flatten/Write/0 >\n",
      "I0124 19:59:36.138300 140304687015680 bundle_processor.py:291] start <FlattenOperation GroupBundleAndTriggers/Flatten/Transcode/0 >\n",
      "I0124 19:59:36.141283 140304687015680 bundle_processor.py:291] start <DoOperation GroupBundleAndTriggers/pair_with_trigger_labels_pair_lists output_tags=['out']>\n",
      "I0124 19:59:36.145181 140304687015680 bundle_processor.py:291] start <DoOperation CreateTriggerLabelsPairLists output_tags=['out']>\n",
      "I0124 19:59:36.148277 140304687015680 bundle_processor.py:291] start <DataInputOperation GroupEventLabelsByPatientId/Read receivers=[ConsumerSet[GroupEventLabelsByPatientId/Read.out0, coder=WindowedValueCoder[TupleCoder[BytesCoder, IterableCoder[LengthPrefixCoder[ProtoCoder]]]], len(consumers)=1]]>\n",
      "I0124 19:59:36.250514 140304687015680 bundle_processor.py:303] finish <DataInputOperation GroupEventLabelsByPatientId/Read receivers=[ConsumerSet[GroupEventLabelsByPatientId/Read.out0, coder=WindowedValueCoder[TupleCoder[BytesCoder, IterableCoder[LengthPrefixCoder[ProtoCoder]]]], len(consumers)=1]]>\n",
      "I0124 19:59:36.253644 140304687015680 bundle_processor.py:303] finish <DoOperation CreateTriggerLabelsPairLists output_tags=['out'], receivers=[ConsumerSet[CreateTriggerLabelsPairLists.out0, coder=WindowedValueCoder[TupleCoder[BytesCoder, FastPrimitivesCoder]], len(consumers)=1]]>\n",
      "I0124 19:59:36.256314 140304687015680 bundle_processor.py:303] finish <DoOperation GroupBundleAndTriggers/pair_with_trigger_labels_pair_lists output_tags=['out'], receivers=[ConsumerSet[GroupBundleAndTriggers/pair_with_trigger_labels_pair_lists.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 19:59:36.258794 140304687015680 bundle_processor.py:303] finish <FlattenOperation GroupBundleAndTriggers/Flatten/Transcode/0 receivers=[ConsumerSet[GroupBundleAndTriggers/Flatten/Transcode/0.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 19:59:36.261322 140304687015680 bundle_processor.py:303] finish <DataOutputOperation GroupBundleAndTriggers/Flatten/Write/0 >\n",
      "I0124 19:59:36.284951 140304687015680 fn_api_runner.py:912] Running (GroupBundleAndTriggers/Flatten/Read)+(GroupBundleAndTriggers/GroupByKey/Write)\n",
      "I0124 19:59:39.391551 140304687015680 bundle_processor.py:291] start <DataOutputOperation GroupBundleAndTriggers/GroupByKey/Write >\n",
      "I0124 19:59:39.393182 140304687015680 bundle_processor.py:291] start <DataInputOperation GroupBundleAndTriggers/Flatten/Read receivers=[ConsumerSet[GroupBundleAndTriggers/Flatten/Read.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 20:00:11.502813 140304687015680 bundle_processor.py:303] finish <DataInputOperation GroupBundleAndTriggers/Flatten/Read receivers=[ConsumerSet[GroupBundleAndTriggers/Flatten/Read.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], LengthPrefixCoder[FastPrimitivesCoder]]], len(consumers)=1]]>\n",
      "I0124 20:00:11.506118 140304687015680 bundle_processor.py:303] finish <DataOutputOperation GroupBundleAndTriggers/GroupByKey/Write >\n",
      "I0124 20:00:13.473567 140304687015680 fn_api_runner.py:912] Running (GroupBundleAndTriggers/GroupByKey/Read)+((ref_AppliedPTransform_GroupBundleAndTriggers/Map(_merge_tagged_vals_under_key)_21)+((ref_AppliedPTransform_JoinBundleAndTriggers_22)+((ref_AppliedPTransform_Reshuffle1/AddRandomKeys_24)+((ref_AppliedPTransform_Reshuffle1/ReshufflePerKey/Map(reify_timestamps)_26)+(Reshuffle1/ReshufflePerKey/GroupByKey/Write)))))\n",
      "I0124 20:00:17.422750 140304687015680 bundle_processor.py:291] start <DataOutputOperation Reshuffle1/ReshufflePerKey/GroupByKey/Write >\n",
      "I0124 20:00:17.425632 140304687015680 bundle_processor.py:291] start <DoOperation Reshuffle1/ReshufflePerKey/Map(reify_timestamps) output_tags=['out']>\n",
      "I0124 20:00:17.428922 140304687015680 bundle_processor.py:291] start <DoOperation Reshuffle1/AddRandomKeys output_tags=['out']>\n",
      "I0124 20:00:17.432291 140304687015680 bundle_processor.py:291] start <DoOperation JoinBundleAndTriggers output_tags=['out']>\n",
      "I0124 20:00:17.436209 140304687015680 bundle_processor.py:291] start <DoOperation GroupBundleAndTriggers/Map(_merge_tagged_vals_under_key) output_tags=['out']>\n",
      "I0124 20:00:17.439245 140304687015680 bundle_processor.py:291] start <DataInputOperation GroupBundleAndTriggers/GroupByKey/Read receivers=[ConsumerSet[GroupBundleAndTriggers/GroupByKey/Read.out0, coder=WindowedValueCoder[TupleCoder[LengthPrefixCoder[FastPrimitivesCoder], IterableCoder[LengthPrefixCoder[FastPrimitivesCoder]]]], len(consumers)=1]]>\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "p.run().wait_until_finish()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAY!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
