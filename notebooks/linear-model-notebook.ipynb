{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.12\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/68/ec26b2cb070a5760707ec8d9491a24e5be72f4885f265bb04abf70c0f9f1/tensorflow-1.12.0-cp27-cp27mu-manylinux1_x86_64.whl (83.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 83.1MB 274kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow==1.12)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.1.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (0.7.1)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.0.post1)\n",
      "Requirement already satisfied: wheel in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (0.32.3)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (2.0.0)\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow==1.12)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/ae/9840c4837c6f54034ac942b5344396e8c3d74686a9bd29beafdf633cc221/tensorboard-1.12.2-py2-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 13.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.1.0)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.12)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/c2/b7f587c0aaf8bf2201405e8162323037fe8d17aa21d3c7dda811b8d01469/protobuf-3.6.1-cp27-cp27mu-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 22.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (0.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.10.0)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.12)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.16.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.12) (1.14.0)\n",
      "Requirement already satisfied: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.12) (1.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.12) (5.1.1)\n",
      "Requirement already satisfied: futures>=3.1.1; python_version < \"3\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (2.6.11)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from protobuf>=3.6.1->tensorflow==1.12) (40.6.2)\n",
      "Requirement already satisfied: h5py in /usr/local/envs/py2env/lib/python2.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.7.1)\n",
      "Requirement already satisfied: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock>=2.0.0->tensorflow==1.12) (1.1)\n",
      "\u001b[31mgoogle-cloud-monitoring 0.28.0 has requirement google-cloud-core<0.29dev,>=0.28.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-cloud-dataflow 2.0.0 has requirement google-apitools==0.5.10, but you'll have google-apitools 0.5.20 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-cloud-dataflow 2.0.0 has requirement google-cloud-bigquery<0.24.0,>=0.23.0, but you'll have google-cloud-bigquery 0.25.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-cloud-dataflow 2.0.0 has requirement httplib2<0.10,>=0.8, but you'll have httplib2 0.11.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-cloud-dataflow 2.0.0 has requirement protobuf==3.2.0, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, protobuf, tensorboard, keras-applications, tensorflow\n",
      "  Found existing installation: protobuf 3.6.0\n",
      "    Uninstalling protobuf-3.6.0:\n",
      "      Successfully uninstalled protobuf-3.6.0\n",
      "  Found existing installation: tensorboard 1.8.0\n",
      "    Uninstalling tensorboard-1.8.0:\n",
      "      Successfully uninstalled tensorboard-1.8.0\n",
      "  Found existing installation: tensorflow 1.8.0\n",
      "    Uninstalling tensorflow-1.8.0:\n",
      "      Successfully uninstalled tensorflow-1.8.0\n",
      "Successfully installed keras-applications-1.0.6 keras-preprocessing-1.0.5 protobuf-3.6.1 tensorboard-1.12.2 tensorflow-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "import os\n",
    "print tf.__version__\n",
    "# Either set the path to the directory with the generated tf.SequenceExamples split into train and validation sets\n",
    "# or set it to a directory in which to store synthtically generated examples.\n",
    "path = '/tmp/'\n",
    "output_dir = '/tmp/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'gs://healthedatalab/seqex/input/seqex_training.tfrecord'\n",
    "validation_file = 'gs://healthedatalab/seqex/input/seqex_validation.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "### Declare Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hparams(hparams_overrides=None):\n",
    "  \"\"\"Creates default HParams with the option of overrides.\n",
    "\n",
    "  Args:\n",
    "    hparams_overrides: HParams overriding the otherwise provided defaults.\n",
    "      Defaults to None (meaning no overrides take place). HParams specified need\n",
    "      to be a referencing a subset of the defaults.\n",
    "\n",
    "  Returns:\n",
    "    Default HParams.\n",
    "  \"\"\"\n",
    "  hparams = tf.contrib.training.HParams(\n",
    "      # Sequence features are bucketed by their age at time of prediction in:\n",
    "      # [time_windows[0] - time_windows[1]),\n",
    "      # [time_windows[1] - time_windows[2]),\n",
    "      # ...\n",
    "      time_windows=[\n",
    "          5 * 365 * 24 * 60 * 60,  # 5 years\n",
    "          365 * 24 * 60 * 60,  # 1 year\n",
    "          30 * 24 * 60 * 60,  # 1 month\n",
    "          7 * 24 * 60 * 60,  # 1 week\n",
    "          1 * 24 * 60 * 60,  # 1 day\n",
    "          0,  # now\n",
    "      ],\n",
    "      batch_size=64,\n",
    "      learning_rate=0.003,\n",
    "      dedup=True,\n",
    "      l1_regularization_strength=0.0,\n",
    "      l2_regularization_strength=0.0,\n",
    "      include_age=True,\n",
    "      age_boundaries=[1, 5, 18, 30, 50, 70, 90],\n",
    "      categorical_context_features=['Patient.gender'],\n",
    "      sequence_features=[\n",
    "          'Composition.section.text.div.tokenized',\n",
    "          'Composition.type',\n",
    "          'Condition.code',\n",
    "          'Encounter.hospitalization.admitSource',\n",
    "          'Encounter.reason.hcc',\n",
    "          'MedicationRequest.contained.medication.code.gsn',\n",
    "          'Procedure.code.cpt',\n",
    "      ],\n",
    "      # Number of hash buckets to map the tokens of the sequence_features into.\n",
    "      sequence_bucket_sizes=[\n",
    "          17000,\n",
    "          16,\n",
    "          3052,\n",
    "          10,\n",
    "          62,\n",
    "          1600,\n",
    "          732,\n",
    "      ],\n",
    "      # List of strings each of which is a ':'-separated list of feature that we\n",
    "      # want to concatenate over the time dimension\n",
    "      time_crossed_features=[\n",
    "          '%s:%s:%s:%s' % ('Observation.code',\n",
    "                           'Observation.value.quantity.value',\n",
    "                           'Observation.value.quantity.unit',\n",
    "                           'Observation.value.string')\n",
    "      ],\n",
    "      time_concat_bucket_sizes=[39571],\n",
    "      context_bucket_sizes=[4])\n",
    "  # Other overrides (possibly coming from vizier) are applied.\n",
    "  if hparams_overrides:\n",
    "    hparams = tf.training.merge_hparam(hparams, hparams_overrides)\n",
    "  return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_KEY_PREFIX = 'c-'\n",
    "SEQUENCE_KEY_PREFIX = 's-'\n",
    "AGE_KEY = 'Patient.ageInYears'\n",
    "\n",
    "LABEL_VALUES = ['less_or_equal_3', '3_7', '7_14', 'above_14']\n",
    "\n",
    "\n",
    "def _example_index_to_sparse_index(example_indices, batch_size):\n",
    "  \"\"\"Creates a sparse index tensor from a list of example indices.\n",
    "\n",
    "  For example, this would do the transformation:\n",
    "  [0, 0, 0, 1, 3, 3] -> [[0,0], [0,1], [0,2], [1,0], [3,0], [3,1]]\n",
    "\n",
    "  The second column of the output tensor is the running count of the occurrences\n",
    "  of that example index.\n",
    "\n",
    "  Args:\n",
    "    example_indices: A sorted 1D Tensor with example indices.\n",
    "    batch_size: The batch_size. Could be larger than max(example_indices) if the\n",
    "      last examples of the batch do not have the feature present.\n",
    "  Returns:\n",
    "    The sparse index tensor.\n",
    "    The maxmium length of a row in this tensor.\n",
    "  \"\"\"\n",
    "  binned_counts = tf.bincount(example_indices, minlength=batch_size)\n",
    "  max_len = tf.to_int64(tf.reduce_max(binned_counts))\n",
    "  return tf.where(tf.sequence_mask(binned_counts)), max_len\n",
    "\n",
    "def _dedup_tensor(sp_tensor):\n",
    "  \"\"\"Dedup values of a SparseTensor along each row.\n",
    "\n",
    "  Args:\n",
    "    sp_tensor: A 2D SparseTensor to be deduped.\n",
    "  Returns:\n",
    "    A deduped SparseTensor of shape [batch_size, max_len], where max_len is\n",
    "    the maximum number of unique values for a row in the Tensor.\n",
    "  \"\"\"\n",
    "  string_batch_index = tf.as_string(sp_tensor.indices[:, 0])\n",
    "\n",
    "  # tf.unique only works on 1D tensors. To avoid deduping across examples,\n",
    "  # prepend each feature value with the example index. This requires casting\n",
    "  # to and from strings for non-string features.\n",
    "  original_dtype = sp_tensor.values.dtype\n",
    "  string_values = (\n",
    "      sp_tensor.values\n",
    "      if original_dtype == tf.string else tf.as_string(sp_tensor.values))\n",
    "  index_and_value = tf.string_join([string_batch_index, string_values],\n",
    "                                   separator='|')\n",
    "  unique_index_and_value, _ = tf.unique(index_and_value)\n",
    "\n",
    "  # split is a shape [tf.size(values), 2] tensor. The first column contains\n",
    "  # indices and the second column contains the feature value (we assume no\n",
    "  # feature contains | so we get exactly 2 values from the string split).\n",
    "  split = tf.string_split(unique_index_and_value, delimiter='|')\n",
    "  split = tf.reshape(split.values, [-1, 2])\n",
    "  string_indices = split[:, 0]\n",
    "  values = split[:, 1]\n",
    "\n",
    "  indices = tf.reshape(\n",
    "      tf.string_to_number(string_indices, out_type=tf.int32), [-1])\n",
    "  if original_dtype != tf.string:\n",
    "    values = tf.string_to_number(values, out_type=original_dtype)\n",
    "  values = tf.reshape(values, [-1])\n",
    "  # Convert example indices into SparseTensor indices, e.g.\n",
    "  # [0, 0, 0, 1, 3, 3] -> [[0,0], [0,1], [0,2], [1,0], [3,0], [3,1]]\n",
    "  batch_size = tf.to_int32(sp_tensor.dense_shape[0])\n",
    "  new_indices, max_len = _example_index_to_sparse_index(indices, batch_size)\n",
    "  return tf.SparseTensor(\n",
    "      indices=tf.to_int64(new_indices),\n",
    "      values=values,\n",
    "      dense_shape=[tf.to_int64(batch_size), max_len])\n",
    "\n",
    "def get_input_fn(mode,\n",
    "                 input_pattern,\n",
    "                 dedup,\n",
    "                 time_windows,\n",
    "                 include_age,\n",
    "                 categorical_context_features,\n",
    "                 sequence_features,\n",
    "                 time_crossed_features,\n",
    "                 batch_size,\n",
    "                 shuffle=True):\n",
    "  \"\"\"Creates an input function to an estimator.\n",
    "\n",
    "  Args:\n",
    "    mode: The execution mode, as defined in tf.estimator.ModeKeys.\n",
    "    input_pattern: Input data pattern in TFRecord format containing\n",
    "      tf.SequenceExamples.\n",
    "    dedup: Whether to remove duplicate values.\n",
    "    time_windows: List of time windows - we bucket all sequence features by\n",
    "      their age into buckets [time_windows[i], time_windows[i+1]).\n",
    "    include_age: Whether to include the age_in_years as a feature.\n",
    "    categorical_context_features: List of string context features that are valid\n",
    "      keys in the tf.SequenceExample.\n",
    "    sequence_features: List of sequence features (strings) that are valid keys\n",
    "      in the tf.SequenceExample.\n",
    "    time_crossed_features: List of list of sequence features (strings) that\n",
    "      should be crossed at each step along the time dimension.\n",
    "    batch_size: The size of the batch when reading in data.\n",
    "    shuffle: Whether to shuffle the examples.\n",
    "\n",
    "  Returns:\n",
    "    A function that returns a dictionary of features and the target labels.\n",
    "  \"\"\"\n",
    "\n",
    "  def input_fn():\n",
    "    \"\"\"Supplies input to our model.\n",
    "\n",
    "    This function supplies input to our model, where this input is a\n",
    "    function of the mode. For example, we supply different data if\n",
    "    we're performing training versus evaluation.\n",
    "\n",
    "    Returns:\n",
    "      A tuple consisting of 1) a dictionary of tensors whose keys are\n",
    "      the feature names, and 2) a tensor of target labels if the mode\n",
    "      is not INFER (and None, otherwise).\n",
    "    \"\"\"\n",
    "\n",
    "    sequence_features_config = dict()\n",
    "    for feature in sequence_features:\n",
    "      dtype = tf.string\n",
    "      if feature == 'Observation.value.quantity.value':\n",
    "        dtype = tf.float32\n",
    "      sequence_features_config[feature] = tf.VarLenFeature(dtype)\n",
    "\n",
    "    sequence_features_config['eventId'] = tf.FixedLenSequenceFeature(\n",
    "        [], tf.int64, allow_missing=False)\n",
    "    for cross in time_crossed_features:\n",
    "      for feature in cross:\n",
    "        dtype = tf.string\n",
    "        if feature == 'Observation.value.quantity.value':\n",
    "          dtype = tf.float32\n",
    "        sequence_features_config[feature] = tf.VarLenFeature(dtype)\n",
    "    context_features_config = dict()\n",
    "    if include_age:\n",
    "      context_features_config['timestamp'] = tf.FixedLenFeature(\n",
    "          [], tf.int64, default_value=-1)\n",
    "      context_features_config['Patient.birthDate'] = tf.FixedLenFeature(\n",
    "          [], tf.int64, default_value=-1)\n",
    "    context_features_config['sequenceLength'] = tf.FixedLenFeature(\n",
    "        [], tf.int64, default_value=-1)\n",
    "\n",
    "    for context_feature in categorical_context_features:\n",
    "      context_features_config[context_feature] = tf.VarLenFeature(tf.string)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "      context_features_config['label.length_of_stay_range.class'] = (\n",
    "          tf.FixedLenFeature([], tf.string, default_value='MISSING'))\n",
    "\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    num_epochs = None if is_training else 1\n",
    "\n",
    "    with tf.name_scope('read_batch'):\n",
    "      file_names = [input_pattern]\n",
    "      files = tf.data.Dataset.list_files(file_names)\n",
    "      if shuffle:\n",
    "        files = files.shuffle(buffer_size=len(file_names))\n",
    "      dataset = (files\n",
    "                 .apply(tf.contrib.data.parallel_interleave(\n",
    "                     tf.data.TFRecordDataset, cycle_length=10))\n",
    "                 .repeat(num_epochs))\n",
    "      if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=100)\n",
    "      dataset = dataset.batch(batch_size)\n",
    "\n",
    "      def _parse_fn(serialized_examples):\n",
    "        context, sequence, _ = tf.io.parse_sequence_example(\n",
    "            serialized_examples,\n",
    "            context_features=context_features_config,\n",
    "            sequence_features=sequence_features_config,\n",
    "            name='parse_sequence_example')\n",
    "        return context, sequence\n",
    "\n",
    "      dataset = dataset.map(_parse_fn, num_parallel_calls=8)\n",
    "\n",
    "      def _process(context, sequence):\n",
    "        \"\"\"Supplies input to our model.\n",
    "\n",
    "        This function supplies input to our model after parsing.\n",
    "\n",
    "        Args:\n",
    "          context: The dictionary from key to (Sparse)Tensors with context\n",
    "            features\n",
    "          sequence: The dictionary from key to (Sparse)Tensors with sequence\n",
    "            features\n",
    "\n",
    "        Returns:\n",
    "          A tuple consisting of 1) a dictionary of tensors whose keys are\n",
    "          the feature names, and 2) a tensor of target labels if the mode\n",
    "          is not INFER (and None, otherwise).\n",
    "        \"\"\"\n",
    "        # Combine into a single dictionary.\n",
    "        feature_map = {}\n",
    "        # Add age if requested.\n",
    "        if include_age:\n",
    "          age_in_seconds = (\n",
    "              context['timestamp'] -\n",
    "              context.pop('Patient.birthDate'))\n",
    "          age_in_years = tf.to_float(age_in_seconds) / (60 * 60 * 24 * 365.0)\n",
    "          feature_map[CONTEXT_KEY_PREFIX + AGE_KEY] = age_in_years\n",
    "\n",
    "        sequence_length = context.pop('sequenceLength')\n",
    "        # Cross the requested features.\n",
    "        for cross in time_crossed_features:\n",
    "          # The features may be missing at different rates - we take the union\n",
    "          # of the indices supplying defaults.\n",
    "          extended_features = dict()\n",
    "          dense_shape = tf.concat(\n",
    "              [[tf.shape(sequence_length)[0]], [tf.reduce_max(sequence_length)],\n",
    "               tf.constant([1], dtype=tf.int64)],\n",
    "              axis=0)\n",
    "          for i, feature in enumerate(cross):\n",
    "            sp_tensor = sequence[feature]\n",
    "            additional_indices = []\n",
    "            covered_indices = sp_tensor.indices\n",
    "            for j, other_feature in enumerate(cross):\n",
    "              if i != j:\n",
    "                additional_indices.append(\n",
    "                    tf.sets.set_difference(\n",
    "                        tf.sparse_reorder(\n",
    "                            tf.SparseTensor(\n",
    "                                indices=sequence[other_feature].indices,\n",
    "                                values=tf.zeros([\n",
    "                                    tf.shape(sequence[other_feature].indices)[0]\n",
    "                                ],\n",
    "                                                dtype=tf.int32),\n",
    "                                dense_shape=dense_shape)),\n",
    "                        tf.sparse_reorder(\n",
    "                            tf.SparseTensor(\n",
    "                                indices=covered_indices,\n",
    "                                values=tf.zeros([tf.shape(covered_indices)[0]],\n",
    "                                                dtype=tf.int32),\n",
    "                                dense_shape=dense_shape))).indices)\n",
    "                covered_indices = tf.concat(\n",
    "                    [sp_tensor.indices] + additional_indices, axis=0)\n",
    "\n",
    "            additional_indices = tf.concat(additional_indices, axis=0)\n",
    "\n",
    "            # Supply defaults for all other indices.\n",
    "            default = tf.tile(\n",
    "                tf.constant(['n/a']),\n",
    "                multiples=[tf.shape(additional_indices)[0]])\n",
    "\n",
    "            string_value = (\n",
    "                tf.as_string(sp_tensor.values)\n",
    "                if sp_tensor.values.dtype != tf.string else sp_tensor.values)\n",
    "\n",
    "            extended_features[feature] = tf.sparse_reorder(\n",
    "                tf.SparseTensor(\n",
    "                    indices=tf.concat([sp_tensor.indices, additional_indices],\n",
    "                                      axis=0),\n",
    "                    values=tf.concat([string_value, default], axis=0),\n",
    "                    dense_shape=dense_shape))\n",
    "\n",
    "          new_values = tf.string_join(\n",
    "              [extended_features[f].values for f in cross], separator='-')\n",
    "          crossed_sp_tensor = tf.sparse_reorder(\n",
    "              tf.SparseTensor(\n",
    "                  indices=extended_features[cross[0]].indices,\n",
    "                  values=new_values,\n",
    "                  dense_shape=extended_features[cross[0]].dense_shape))\n",
    "          sequence['_'.join(cross)] = crossed_sp_tensor\n",
    "        # Remove unwanted features that are used in the cross but should not be\n",
    "        # considered outside the cross.\n",
    "        for cross in time_crossed_features:\n",
    "          for feature in cross:\n",
    "            if feature not in sequence_features and feature in sequence:\n",
    "              del sequence[feature]\n",
    "\n",
    "        # Flatten sparse tensor to compute event age. This dense tensor also\n",
    "        # contains padded values. These will not be used when gathering elements\n",
    "        # from the dense tensor since each sparse feature won't have a value\n",
    "        # defined for the padding.\n",
    "        padded_event_age = (\n",
    "            # Broadcast current time along sequence dimension.\n",
    "            tf.expand_dims(context.pop('timestamp'), 1)\n",
    "            # Subtract time of events.\n",
    "            - sequence.pop('eventId'))\n",
    "\n",
    "        for i in range(len(time_windows) - 1):\n",
    "          max_age = time_windows[i]\n",
    "          min_age = time_windows[i+1]\n",
    "          padded_in_time_window = tf.logical_and(padded_event_age <= max_age,\n",
    "                                                 padded_event_age > min_age)\n",
    "\n",
    "          for k, v in sequence.items():\n",
    "            # For each sparse feature entry, look up whether it is in the time\n",
    "            # window or not.\n",
    "            in_time_window = tf.gather_nd(padded_in_time_window,\n",
    "                                          v.indices[:, 0:2])\n",
    "            v = tf.sparse_retain(v, in_time_window)\n",
    "            sp_tensor = tf.sparse_reshape(v, [v.dense_shape[0], -1])\n",
    "            if dedup:\n",
    "              sp_tensor = _dedup_tensor(sp_tensor)\n",
    "\n",
    "            feature_map[SEQUENCE_KEY_PREFIX + k +\n",
    "                        '-til-%d' %min_age] = sp_tensor\n",
    "\n",
    "        for k, v in context.items():\n",
    "          feature_map[CONTEXT_KEY_PREFIX + k] = v\n",
    "        return feature_map\n",
    "\n",
    "      feature_map = (dataset\n",
    "                     # Parallelize the input processing and put it behind a\n",
    "                     # queue to increase performance by removing it from the\n",
    "                     # critical path of per-step-computation.\n",
    "                     .map(_process, num_parallel_calls=8)\n",
    "                     .prefetch(buffer_size=1)\n",
    "                     .make_one_shot_iterator()\n",
    "                     .get_next())\n",
    "      label = None\n",
    "      if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label = feature_map.pop(CONTEXT_KEY_PREFIX +\n",
    "                                'label.length_of_stay_range.class')\n",
    "      return feature_map, label\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-c2e15f6954a2>:159: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'s-Observation.code_Observation.value.quantity.value_Observation.value.quantity.unit_Observation.value.string-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.section.text.div.tokenized-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Observation.code_Observation.value.quantity.value_Observation.value.quantity.unit_Observation.value.string-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.section.text.div.tokenized-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Condition.code-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.reason.hcc-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Observation.code_Observation.value.quantity.value_Observation.value.quantity.unit_Observation.value.string-til-2592000': SparseTensorValue(indices=array([[  0,   0],\n",
      "       [  0,   1],\n",
      "       [  0,   2],\n",
      "       [  0,   3],\n",
      "       [  0,   4],\n",
      "       [  0,   5],\n",
      "       [  0,   6],\n",
      "       [  0,   7],\n",
      "       [  0,   8],\n",
      "       [  0,   9],\n",
      "       [  0,  10],\n",
      "       [  0,  11],\n",
      "       [  0,  12],\n",
      "       [  0,  13],\n",
      "       [  0,  14],\n",
      "       [  0,  15],\n",
      "       [  0,  16],\n",
      "       [  0,  17],\n",
      "       [  0,  18],\n",
      "       [  0,  19],\n",
      "       [  0,  20],\n",
      "       [  0,  21],\n",
      "       [  0,  22],\n",
      "       [  0,  23],\n",
      "       [  0,  24],\n",
      "       [  0,  25],\n",
      "       [  0,  26],\n",
      "       [  0,  27],\n",
      "       [  0,  28],\n",
      "       [  0,  29],\n",
      "       [  0,  30],\n",
      "       [  0,  31],\n",
      "       [  0,  32],\n",
      "       [  0,  33],\n",
      "       [  0,  34],\n",
      "       [  0,  35],\n",
      "       [  0,  36],\n",
      "       [  0,  37],\n",
      "       [  0,  38],\n",
      "       [  0,  39],\n",
      "       [  0,  40],\n",
      "       [  0,  41],\n",
      "       [  0,  42],\n",
      "       [  0,  43],\n",
      "       [  0,  44],\n",
      "       [  0,  45],\n",
      "       [  0,  46],\n",
      "       [  0,  47],\n",
      "       [  0,  48],\n",
      "       [  0,  49],\n",
      "       [  0,  50],\n",
      "       [  0,  51],\n",
      "       [  0,  52],\n",
      "       [  0,  53],\n",
      "       [  0,  54],\n",
      "       [  0,  55],\n",
      "       [  0,  56],\n",
      "       [  0,  57],\n",
      "       [  0,  58],\n",
      "       [  0,  59],\n",
      "       [  0,  60],\n",
      "       [  0,  61],\n",
      "       [  0,  62],\n",
      "       [  0,  63],\n",
      "       [  0,  64],\n",
      "       [  0,  65],\n",
      "       [  0,  66],\n",
      "       [  0,  67],\n",
      "       [  0,  68],\n",
      "       [  0,  69],\n",
      "       [  0,  70],\n",
      "       [  0,  71],\n",
      "       [  0,  72],\n",
      "       [  0,  73],\n",
      "       [  0,  74],\n",
      "       [  0,  75],\n",
      "       [  0,  76],\n",
      "       [  0,  77],\n",
      "       [  0,  78],\n",
      "       [  0,  79],\n",
      "       [  0,  80],\n",
      "       [  0,  81],\n",
      "       [  0,  82],\n",
      "       [  0,  83],\n",
      "       [  0,  84],\n",
      "       [  0,  85],\n",
      "       [  0,  86],\n",
      "       [  0,  87],\n",
      "       [  0,  88],\n",
      "       [  0,  89],\n",
      "       [  0,  90],\n",
      "       [  0,  91],\n",
      "       [  0,  92],\n",
      "       [  0,  93],\n",
      "       [  0,  94],\n",
      "       [  0,  95],\n",
      "       [  0,  96],\n",
      "       [  0,  97],\n",
      "       [  0,  98],\n",
      "       [  0,  99],\n",
      "       [  0, 100],\n",
      "       [  0, 101],\n",
      "       [  0, 102],\n",
      "       [  0, 103],\n",
      "       [  0, 104],\n",
      "       [  0, 105],\n",
      "       [  0, 106],\n",
      "       [  0, 107],\n",
      "       [  0, 108],\n",
      "       [  0, 109],\n",
      "       [  0, 110],\n",
      "       [  0, 111],\n",
      "       [  0, 112],\n",
      "       [  0, 113],\n",
      "       [  1,   0],\n",
      "       [  1,   1],\n",
      "       [  1,   2],\n",
      "       [  1,   3],\n",
      "       [  1,   4],\n",
      "       [  1,   5],\n",
      "       [  1,   6],\n",
      "       [  1,   7],\n",
      "       [  1,   8],\n",
      "       [  1,   9],\n",
      "       [  1,  10],\n",
      "       [  1,  11],\n",
      "       [  1,  12],\n",
      "       [  1,  13],\n",
      "       [  1,  14],\n",
      "       [  1,  15],\n",
      "       [  1,  16],\n",
      "       [  1,  17],\n",
      "       [  1,  18],\n",
      "       [  1,  19],\n",
      "       [  1,  20],\n",
      "       [  1,  21],\n",
      "       [  1,  22],\n",
      "       [  1,  23],\n",
      "       [  1,  24],\n",
      "       [  1,  25],\n",
      "       [  1,  26],\n",
      "       [  1,  27],\n",
      "       [  1,  28],\n",
      "       [  1,  29],\n",
      "       [  1,  30],\n",
      "       [  1,  31],\n",
      "       [  1,  32],\n",
      "       [  1,  33],\n",
      "       [  1,  34],\n",
      "       [  1,  35],\n",
      "       [  1,  36],\n",
      "       [  1,  37],\n",
      "       [  1,  38],\n",
      "       [  1,  39],\n",
      "       [  1,  40],\n",
      "       [  1,  41],\n",
      "       [  1,  42],\n",
      "       [  1,  43],\n",
      "       [  1,  44],\n",
      "       [  1,  45],\n",
      "       [  1,  46],\n",
      "       [  1,  47],\n",
      "       [  1,  48],\n",
      "       [  1,  49],\n",
      "       [  1,  50],\n",
      "       [  1,  51],\n",
      "       [  1,  52],\n",
      "       [  1,  53],\n",
      "       [  1,  54],\n",
      "       [  1,  55],\n",
      "       [  1,  56],\n",
      "       [  1,  57],\n",
      "       [  1,  58],\n",
      "       [  1,  59],\n",
      "       [  1,  60],\n",
      "       [  1,  61],\n",
      "       [  1,  62],\n",
      "       [  1,  63],\n",
      "       [  1,  64],\n",
      "       [  1,  65],\n",
      "       [  1,  66],\n",
      "       [  1,  67],\n",
      "       [  1,  68],\n",
      "       [  1,  69],\n",
      "       [  1,  70],\n",
      "       [  1,  71],\n",
      "       [  1,  72],\n",
      "       [  1,  73],\n",
      "       [  1,  74],\n",
      "       [  1,  75],\n",
      "       [  1,  76],\n",
      "       [  1,  77],\n",
      "       [  1,  78],\n",
      "       [  1,  79],\n",
      "       [  1,  80],\n",
      "       [  1,  81],\n",
      "       [  1,  82],\n",
      "       [  1,  83],\n",
      "       [  1,  84],\n",
      "       [  1,  85],\n",
      "       [  1,  86],\n",
      "       [  1,  87],\n",
      "       [  1,  88],\n",
      "       [  1,  89],\n",
      "       [  1,  90],\n",
      "       [  1,  91],\n",
      "       [  1,  92],\n",
      "       [  1,  93],\n",
      "       [  1,  94],\n",
      "       [  1,  95],\n",
      "       [  1,  96],\n",
      "       [  1,  97],\n",
      "       [  1,  98],\n",
      "       [  1,  99],\n",
      "       [  1, 100],\n",
      "       [  1, 101],\n",
      "       [  1, 102],\n",
      "       [  1, 103],\n",
      "       [  1, 104]]), values=array(['loinc:49765-1-9.822818-mg/dL-n/a',\n",
      "       'loinc:39156-5-34.128902-kg/m2-n/a',\n",
      "       'loinc:14959-1-152.291306-mg/g-n/a',\n",
      "       'loinc:2085-9-37.386253-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.979628-mg/dL-n/a',\n",
      "       'loinc:2069-3-110.937637-mmol/L-n/a', 'loinc:72166-2-n/a-n/a-n/a',\n",
      "       'loinc:2947-0-137.940170-mmol/L-n/a',\n",
      "       'loinc:29463-7-100.707916-kg-n/a',\n",
      "       'loinc:6298-4-5.083851-mmol/L-n/a',\n",
      "       'loinc:8302-2-171.779221-cm-n/a',\n",
      "       'loinc:18262-6-119.242416-mg/dL-n/a', 'loinc:55284-4-n/a-n/a-n/a',\n",
      "       'loinc:2571-8-452.913391-mg/dL-n/a',\n",
      "       'loinc:20565-8-20.266193-mmol/L-n/a',\n",
      "       'loinc:33914-3-24.954391-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2339-0-143.709274-mg/dL-n/a',\n",
      "       'loinc:6299-2-12.726696-mg/dL-n/a',\n",
      "       'loinc:2093-3-247.211349-mg/dL-n/a', 'loinc:4548-4-4.032226-%-n/a',\n",
      "       'loinc:72514-3-3.141857-{score}-n/a',\n",
      "       'loinc:2571-8-217.673233-mg/dL-n/a',\n",
      "       'loinc:2069-3-107.479454-mmol/L-n/a',\n",
      "       'loinc:72514-3-0.743203-{score}-n/a',\n",
      "       'loinc:6299-2-7.427403-mg/dL-n/a',\n",
      "       'loinc:14959-1-206.023926-mg/g-n/a',\n",
      "       'loinc:2339-0-158.614822-mg/dL-n/a',\n",
      "       'loinc:2085-9-21.399632-mg/dL-n/a',\n",
      "       'loinc:33914-3-15.700432-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:38483-4-6.325252-mg/dL-n/a',\n",
      "       'loinc:2093-3-253.135452-mg/dL-n/a',\n",
      "       'loinc:20565-8-26.184303-mmol/L-n/a',\n",
      "       'loinc:49765-1-8.652967-mg/dL-n/a',\n",
      "       'loinc:18262-6-188.201172-mg/dL-n/a',\n",
      "       'loinc:2947-0-139.660706-mmol/L-n/a',\n",
      "       'loinc:6298-4-4.886987-mmol/L-n/a',\n",
      "       'loinc:2339-0-195.667831-mg/dL-n/a',\n",
      "       'loinc:2093-3-242.310318-mg/dL-n/a',\n",
      "       'loinc:18262-6-134.699417-mg/dL-n/a',\n",
      "       'loinc:14959-1-265.496155-mg/g-n/a',\n",
      "       'loinc:38483-4-6.046712-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.825174-{score}-n/a',\n",
      "       'loinc:20565-8-27.107983-mmol/L-n/a',\n",
      "       'loinc:49765-1-10.169772-mg/dL-n/a',\n",
      "       'loinc:6298-4-3.834455-mmol/L-n/a',\n",
      "       'loinc:33914-3-16.423668-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2947-0-140.114960-mmol/L-n/a',\n",
      "       'loinc:2571-8-355.645874-mg/dL-n/a',\n",
      "       'loinc:6299-2-14.209026-mg/dL-n/a',\n",
      "       'loinc:2069-3-108.266739-mmol/L-n/a',\n",
      "       'loinc:2085-9-36.481712-mg/dL-n/a',\n",
      "       'loinc:6298-4-3.793260-mmol/L-n/a',\n",
      "       'loinc:2093-3-241.767670-mg/dL-n/a',\n",
      "       'loinc:18262-6-121.979187-mg/dL-n/a',\n",
      "       'loinc:2085-9-37.753181-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.805751-{score}-n/a',\n",
      "       'loinc:2069-3-101.970383-mmol/L-n/a',\n",
      "       'loinc:2947-0-142.023499-mmol/L-n/a',\n",
      "       'loinc:2571-8-410.176453-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.948173-mg/dL-n/a',\n",
      "       'loinc:33914-3-25.153204-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:6299-2-14.019806-mg/dL-n/a',\n",
      "       'loinc:20565-8-28.373087-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.241428-mg/dL-n/a',\n",
      "       'loinc:14959-1-113.020683-mg/g-n/a',\n",
      "       'loinc:2339-0-193.535873-mg/dL-n/a',\n",
      "       'loinc:6299-2-18.331600-mg/dL-n/a',\n",
      "       'loinc:2093-3-242.479614-mg/dL-n/a',\n",
      "       'loinc:2571-8-296.219360-mg/dL-n/a',\n",
      "       'loinc:2085-9-23.180655-mg/dL-n/a',\n",
      "       'loinc:2947-0-136.405487-mmol/L-n/a',\n",
      "       'loinc:14959-1-175.845734-mg/g-n/a',\n",
      "       'loinc:38483-4-5.541221-mg/dL-n/a',\n",
      "       'loinc:2069-3-102.271065-mmol/L-n/a',\n",
      "       'loinc:20565-8-21.805401-mmol/L-n/a',\n",
      "       'loinc:2339-0-195.125397-mg/dL-n/a',\n",
      "       'loinc:18262-6-160.055084-mg/dL-n/a',\n",
      "       'loinc:49765-1-9.730612-mg/dL-n/a',\n",
      "       'loinc:72514-3-1.996203-{score}-n/a',\n",
      "       'loinc:6298-4-4.121016-mmol/L-n/a',\n",
      "       'loinc:33914-3-17.921898-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:14959-1-52.885647-mg/g-n/a',\n",
      "       'loinc:20565-8-28.270506-mmol/L-n/a',\n",
      "       'loinc:49765-1-8.745844-mg/dL-n/a',\n",
      "       'loinc:18262-6-173.696289-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.740440-mg/dL-n/a',\n",
      "       'loinc:6299-2-9.810800-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.317147-{score}-n/a',\n",
      "       'loinc:2571-8-285.362885-mg/dL-n/a',\n",
      "       'loinc:2085-9-26.485680-mg/dL-n/a',\n",
      "       'loinc:2093-3-257.254547-mg/dL-n/a',\n",
      "       'loinc:2069-3-109.932518-mmol/L-n/a',\n",
      "       'loinc:6298-4-4.581605-mmol/L-n/a',\n",
      "       'loinc:2339-0-125.190750-mg/dL-n/a',\n",
      "       'loinc:33914-3-26.550137-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2947-0-139.303543-mmol/L-n/a',\n",
      "       'loinc:2093-3-242.219971-mg/dL-n/a',\n",
      "       'loinc:2339-0-144.502289-mg/dL-n/a',\n",
      "       'loinc:2947-0-143.826904-mmol/L-n/a',\n",
      "       'loinc:33914-3-21.176538-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2069-3-109.673645-mmol/L-n/a',\n",
      "       'loinc:4548-4-3.872930-%-n/a', 'loinc:6298-4-4.010433-mmol/L-n/a',\n",
      "       'loinc:39156-5-33.491718-kg/m2-n/a',\n",
      "       'loinc:2085-9-26.265936-mg/dL-n/a',\n",
      "       'loinc:49765-1-9.945234-mg/dL-n/a',\n",
      "       'loinc:14959-1-69.550232-mg/g-n/a',\n",
      "       'loinc:2571-8-440.668549-mg/dL-n/a',\n",
      "       'loinc:29463-7-98.827705-kg-n/a',\n",
      "       'loinc:20565-8-26.646385-mmol/L-n/a',\n",
      "       'loinc:18262-6-127.820335-mg/dL-n/a',\n",
      "       'loinc:6299-2-16.150360-mg/dL-n/a',\n",
      "       'loinc:38483-4-4.537214-mg/dL-n/a',\n",
      "       'loinc:72514-3-2.223987-{score}-n/a', 'loinc:32465-7-n/a-n/a-n/a',\n",
      "       'loinc:5799-2-n/a-n/a-n/a', 'loinc:20505-4-0.234034-mg/dL-n/a',\n",
      "       'loinc:49765-1-9.767042-mg/dL-n/a',\n",
      "       'loinc:2339-0-91.785889-mg/dL-n/a',\n",
      "       'loinc:789-8-5.346625-10*6/uL-n/a',\n",
      "       'loinc:38483-4-3.377507-mg/dL-n/a',\n",
      "       'loinc:21000-5-45.968357-fL-n/a', 'loinc:4544-3-44.697865-%-n/a',\n",
      "       'loinc:2514-8-n/a-n/a-n/a', 'loinc:6690-2-2.680371-10*3/uL-n/a',\n",
      "       'loinc:6768-6-65.211586-U/L-n/a', 'loinc:25428-4-n/a-n/a-n/a',\n",
      "       'loinc:1975-2-1.073159-mg/dL-n/a',\n",
      "       'loinc:777-3-366.720032-10*3/uL-n/a', 'loinc:46288-7-n/a-n/a-n/a',\n",
      "       'loinc:6298-4-3.896253-mmol/L-n/a', 'loinc:5794-3-n/a-n/a-n/a',\n",
      "       'loinc:20454-5-n/a-n/a-n/a', 'loinc:5811-5-1.005169-{nominal}-n/a',\n",
      "       'loinc:5797-6-12.965216-mg/dL-n/a', 'loinc:787-2-84.627594-fL-n/a',\n",
      "       'loinc:2857-1-7.444013-ng/mL-n/a', 'loinc:5802-4-n/a-n/a-n/a',\n",
      "       'loinc:10834-0-2.096823-g/L-n/a', 'loinc:32623-1-11.217098-fL-n/a',\n",
      "       'loinc:6299-2-8.071855-mg/dL-n/a',\n",
      "       'loinc:33914-3-19.788584-mL/min-n/a',\n",
      "       'loinc:32207-3-278.383240-fL-n/a',\n",
      "       'loinc:5792-7-1.050634-mg/dL-n/a', 'loinc:32167-9-n/a-n/a-n/a',\n",
      "       'loinc:5778-6-n/a-n/a-n/a', 'loinc:5804-0-408.057831-mg/dL-n/a',\n",
      "       'loinc:5770-3-n/a-n/a-n/a', 'loinc:1751-7-3.739916-g/dL-n/a',\n",
      "       'loinc:5803-2-5.746361-pH-n/a', 'loinc:786-4-33.208054-g/dL-n/a',\n",
      "       'loinc:2069-3-110.179588-mmol/L-n/a',\n",
      "       'loinc:2947-0-140.819550-mmol/L-n/a', 'loinc:5767-9-n/a-n/a-n/a',\n",
      "       'loinc:1742-6-31.589827-U/L-n/a',\n",
      "       'loinc:2885-2-71.312988-g/dL-n/a',\n",
      "       'loinc:20565-8-25.175829-mmol/L-n/a',\n",
      "       'loinc:718-7-14.131288-g/dL-n/a', 'loinc:785-6-29.579519-pg-n/a',\n",
      "       'loinc:1920-8-18.773352-U/L-n/a', 'loinc:55284-4-n/a-n/a-n/a',\n",
      "       'loinc:72514-3-1.810580-{score}-n/a',\n",
      "       'loinc:29463-7-86.447098-kg-n/a', 'loinc:72166-2-n/a-n/a-n/a',\n",
      "       'loinc:8302-2-180.266525-cm-n/a',\n",
      "       'loinc:39156-5-26.602365-kg/m2-n/a',\n",
      "       'loinc:2885-2-76.489182-g/dL-n/a',\n",
      "       'loinc:33914-3-6.366703-mL/min-n/a',\n",
      "       'loinc:32207-3-424.914581-fL-n/a',\n",
      "       'loinc:1975-2-0.932803-mg/dL-n/a',\n",
      "       'loinc:2069-3-110.670387-mmol/L-n/a',\n",
      "       'loinc:5804-0-293.959320-mg/dL-n/a',\n",
      "       'loinc:777-3-397.598602-10*3/uL-n/a',\n",
      "       'loinc:2947-0-136.065857-mmol/L-n/a',\n",
      "       'loinc:10834-0-2.650084-g/L-n/a',\n",
      "       'loinc:5797-6-6.764235-mg/dL-n/a',\n",
      "       'loinc:6299-2-14.692470-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.061598-mg/dL-n/a',\n",
      "       'loinc:6768-6-101.561989-U/L-n/a',\n",
      "       'loinc:32623-1-11.188381-fL-n/a',\n",
      "       'loinc:5792-7-2.307934-mg/dL-n/a',\n",
      "       'loinc:789-8-4.212824-10*6/uL-n/a',\n",
      "       'loinc:6690-2-4.575498-10*3/uL-n/a',\n",
      "       'loinc:21000-5-45.495712-fL-n/a',\n",
      "       'loinc:20505-4-1.470489-mg/dL-n/a',\n",
      "       'loinc:1742-6-34.084011-U/L-n/a', 'loinc:785-6-29.006943-pg-n/a',\n",
      "       'loinc:787-2-87.060112-fL-n/a', 'loinc:1751-7-3.824742-g/dL-n/a',\n",
      "       'loinc:20565-8-28.034174-mmol/L-n/a',\n",
      "       'loinc:49765-1-8.837758-mg/dL-n/a',\n",
      "       'loinc:5811-5-1.020188-{nominal}-n/a',\n",
      "       'loinc:2339-0-96.173592-mg/dL-n/a',\n",
      "       'loinc:786-4-35.959633-g/dL-n/a', 'loinc:5803-2-5.295888-pH-n/a',\n",
      "       'loinc:6298-4-4.538869-mmol/L-n/a', 'loinc:4544-3-43.826473-%-n/a',\n",
      "       'loinc:718-7-14.925654-g/dL-n/a', 'loinc:1920-8-18.503071-U/L-n/a',\n",
      "       'loinc:2885-2-62.280502-g/dL-n/a',\n",
      "       'loinc:33914-3-77.040573-mL/min-n/a',\n",
      "       'loinc:2069-3-104.099625-mmol/L-n/a',\n",
      "       'loinc:10834-0-2.571339-g/L-n/a',\n",
      "       'loinc:2093-3-154.126465-mg/dL-n/a',\n",
      "       'loinc:2339-0-71.076904-mg/dL-n/a',\n",
      "       'loinc:2571-8-107.042511-mg/dL-n/a',\n",
      "       'loinc:2085-9-40.801888-mg/dL-n/a',\n",
      "       'loinc:6299-2-14.055153-mg/dL-n/a',\n",
      "       'loinc:2947-0-141.630890-mmol/L-n/a',\n",
      "       'loinc:1975-2-0.463329-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.080111-mg/dL-n/a',\n",
      "       'loinc:1742-6-48.318607-U/L-n/a',\n",
      "       'loinc:6298-4-4.349833-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.416953-mg/dL-n/a',\n",
      "       'loinc:18262-6-137.244156-mg/dL-n/a',\n",
      "       'loinc:6768-6-75.432449-U/L-n/a',\n",
      "       'loinc:20565-8-23.875072-mmol/L-n/a',\n",
      "       'loinc:1920-8-16.390091-U/L-n/a', 'loinc:1751-7-3.783733-g/dL-n/a'],\n",
      "      dtype=object), dense_shape=array([  2, 114])), 's-Encounter.hospitalization.admitSource-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Procedure.code.cpt-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 'c-Patient.ageInYears': array([70.3087 , 83.24627], dtype=float32), 's-MedicationRequest.contained.medication.code.gsn-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.reason.hcc-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.reason.hcc-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 'label': array(['less_or_equal_3', 'less_or_equal_3'], dtype=object), 's-MedicationRequest.contained.medication.code.gsn-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Observation.code_Observation.value.quantity.value_Observation.value.quantity.unit_Observation.value.string-til-604800': SparseTensorValue(indices=array([[ 0,  0],\n",
      "       [ 0,  1],\n",
      "       [ 0,  2],\n",
      "       [ 0,  3],\n",
      "       [ 0,  4],\n",
      "       [ 0,  5],\n",
      "       [ 0,  6],\n",
      "       [ 0,  7],\n",
      "       [ 0,  8],\n",
      "       [ 0,  9],\n",
      "       [ 0, 10],\n",
      "       [ 0, 11],\n",
      "       [ 0, 12],\n",
      "       [ 0, 13],\n",
      "       [ 0, 14],\n",
      "       [ 0, 15],\n",
      "       [ 0, 16],\n",
      "       [ 0, 17],\n",
      "       [ 0, 18],\n",
      "       [ 0, 19],\n",
      "       [ 0, 20]]), values=array(['loinc:6299-2-13.751298-mg/dL-n/a',\n",
      "       'loinc:39156-5-33.491718-kg/m2-n/a',\n",
      "       'loinc:2339-0-146.195831-mg/dL-n/a',\n",
      "       'loinc:2093-3-249.285080-mg/dL-n/a',\n",
      "       'loinc:72514-3-2.683739-{score}-n/a',\n",
      "       'loinc:18262-6-168.259003-mg/dL-n/a',\n",
      "       'loinc:38483-4-4.391740-mg/dL-n/a', 'loinc:72166-2-n/a-n/a-n/a',\n",
      "       'loinc:55284-4-n/a-n/a-n/a', 'loinc:2069-3-106.292786-mmol/L-n/a',\n",
      "       'loinc:2571-8-211.854980-mg/dL-n/a', 'loinc:4548-4-3.872930-%-n/a',\n",
      "       'loinc:2085-9-38.655087-mg/dL-n/a',\n",
      "       'loinc:33914-3-21.878000-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:20565-8-26.084427-mmol/L-n/a',\n",
      "       'loinc:6298-4-4.790510-mmol/L-n/a',\n",
      "       'loinc:8302-2-171.779221-cm-n/a',\n",
      "       'loinc:49765-1-9.762003-mg/dL-n/a',\n",
      "       'loinc:14959-1-184.205444-mg/g-n/a',\n",
      "       'loinc:2947-0-137.918854-mmol/L-n/a',\n",
      "       'loinc:29463-7-98.827705-kg-n/a'], dtype=object), dense_shape=array([ 2, 21])), 's-Condition.code-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.reason.hcc-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-MedicationRequest.contained.medication.code.gsn-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.type-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Condition.code-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.section.text.div.tokenized-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Procedure.code.cpt-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.type-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.hospitalization.admitSource-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-MedicationRequest.contained.medication.code.gsn-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Condition.code-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.type-til-0': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.section.text.div.tokenized-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Observation.code_Observation.value.quantity.value_Observation.value.quantity.unit_Observation.value.string-til-31536000': SparseTensorValue(indices=array([[  0,   0],\n",
      "       [  0,   1],\n",
      "       [  0,   2],\n",
      "       [  0,   3],\n",
      "       [  0,   4],\n",
      "       [  0,   5],\n",
      "       [  0,   6],\n",
      "       [  0,   7],\n",
      "       [  0,   8],\n",
      "       [  0,   9],\n",
      "       [  0,  10],\n",
      "       [  0,  11],\n",
      "       [  0,  12],\n",
      "       [  0,  13],\n",
      "       [  0,  14],\n",
      "       [  0,  15],\n",
      "       [  0,  16],\n",
      "       [  0,  17],\n",
      "       [  0,  18],\n",
      "       [  0,  19],\n",
      "       [  0,  20],\n",
      "       [  0,  21],\n",
      "       [  0,  22],\n",
      "       [  0,  23],\n",
      "       [  0,  24],\n",
      "       [  0,  25],\n",
      "       [  0,  26],\n",
      "       [  0,  27],\n",
      "       [  0,  28],\n",
      "       [  0,  29],\n",
      "       [  0,  30],\n",
      "       [  0,  31],\n",
      "       [  0,  32],\n",
      "       [  0,  33],\n",
      "       [  0,  34],\n",
      "       [  0,  35],\n",
      "       [  0,  36],\n",
      "       [  0,  37],\n",
      "       [  0,  38],\n",
      "       [  0,  39],\n",
      "       [  0,  40],\n",
      "       [  0,  41],\n",
      "       [  0,  42],\n",
      "       [  0,  43],\n",
      "       [  0,  44],\n",
      "       [  0,  45],\n",
      "       [  0,  46],\n",
      "       [  0,  47],\n",
      "       [  0,  48],\n",
      "       [  0,  49],\n",
      "       [  0,  50],\n",
      "       [  0,  51],\n",
      "       [  0,  52],\n",
      "       [  0,  53],\n",
      "       [  0,  54],\n",
      "       [  0,  55],\n",
      "       [  0,  56],\n",
      "       [  0,  57],\n",
      "       [  0,  58],\n",
      "       [  0,  59],\n",
      "       [  0,  60],\n",
      "       [  0,  61],\n",
      "       [  0,  62],\n",
      "       [  0,  63],\n",
      "       [  0,  64],\n",
      "       [  0,  65],\n",
      "       [  0,  66],\n",
      "       [  0,  67],\n",
      "       [  0,  68],\n",
      "       [  0,  69],\n",
      "       [  0,  70],\n",
      "       [  0,  71],\n",
      "       [  0,  72],\n",
      "       [  0,  73],\n",
      "       [  0,  74],\n",
      "       [  0,  75],\n",
      "       [  0,  76],\n",
      "       [  0,  77],\n",
      "       [  0,  78],\n",
      "       [  0,  79],\n",
      "       [  0,  80],\n",
      "       [  0,  81],\n",
      "       [  0,  82],\n",
      "       [  0,  83],\n",
      "       [  0,  84],\n",
      "       [  0,  85],\n",
      "       [  0,  86],\n",
      "       [  0,  87],\n",
      "       [  0,  88],\n",
      "       [  0,  89],\n",
      "       [  0,  90],\n",
      "       [  0,  91],\n",
      "       [  0,  92],\n",
      "       [  0,  93],\n",
      "       [  0,  94],\n",
      "       [  0,  95],\n",
      "       [  0,  96],\n",
      "       [  0,  97],\n",
      "       [  0,  98],\n",
      "       [  0,  99],\n",
      "       [  0, 100],\n",
      "       [  0, 101],\n",
      "       [  0, 102],\n",
      "       [  0, 103],\n",
      "       [  0, 104],\n",
      "       [  0, 105],\n",
      "       [  0, 106],\n",
      "       [  0, 107],\n",
      "       [  0, 108],\n",
      "       [  0, 109],\n",
      "       [  0, 110],\n",
      "       [  0, 111],\n",
      "       [  0, 112],\n",
      "       [  0, 113],\n",
      "       [  0, 114],\n",
      "       [  0, 115],\n",
      "       [  0, 116],\n",
      "       [  0, 117],\n",
      "       [  0, 118],\n",
      "       [  0, 119],\n",
      "       [  0, 120],\n",
      "       [  0, 121],\n",
      "       [  0, 122],\n",
      "       [  0, 123],\n",
      "       [  0, 124],\n",
      "       [  0, 125],\n",
      "       [  0, 126],\n",
      "       [  0, 127],\n",
      "       [  0, 128],\n",
      "       [  0, 129],\n",
      "       [  0, 130],\n",
      "       [  0, 131],\n",
      "       [  0, 132],\n",
      "       [  0, 133],\n",
      "       [  0, 134],\n",
      "       [  0, 135],\n",
      "       [  0, 136],\n",
      "       [  0, 137],\n",
      "       [  0, 138],\n",
      "       [  0, 139],\n",
      "       [  0, 140],\n",
      "       [  0, 141],\n",
      "       [  0, 142],\n",
      "       [  0, 143],\n",
      "       [  0, 144],\n",
      "       [  0, 145],\n",
      "       [  0, 146],\n",
      "       [  0, 147],\n",
      "       [  0, 148],\n",
      "       [  0, 149],\n",
      "       [  0, 150],\n",
      "       [  0, 151],\n",
      "       [  0, 152],\n",
      "       [  0, 153],\n",
      "       [  0, 154],\n",
      "       [  0, 155],\n",
      "       [  0, 156],\n",
      "       [  0, 157],\n",
      "       [  0, 158],\n",
      "       [  0, 159],\n",
      "       [  0, 160],\n",
      "       [  0, 161],\n",
      "       [  0, 162],\n",
      "       [  0, 163],\n",
      "       [  0, 164],\n",
      "       [  0, 165],\n",
      "       [  0, 166],\n",
      "       [  0, 167],\n",
      "       [  0, 168],\n",
      "       [  0, 169],\n",
      "       [  0, 170],\n",
      "       [  0, 171],\n",
      "       [  0, 172],\n",
      "       [  0, 173],\n",
      "       [  0, 174],\n",
      "       [  0, 175],\n",
      "       [  0, 176],\n",
      "       [  0, 177],\n",
      "       [  0, 178],\n",
      "       [  0, 179],\n",
      "       [  0, 180],\n",
      "       [  0, 181],\n",
      "       [  0, 182],\n",
      "       [  0, 183],\n",
      "       [  0, 184],\n",
      "       [  0, 185],\n",
      "       [  0, 186],\n",
      "       [  0, 187],\n",
      "       [  0, 188],\n",
      "       [  0, 189],\n",
      "       [  0, 190],\n",
      "       [  0, 191],\n",
      "       [  0, 192],\n",
      "       [  0, 193],\n",
      "       [  0, 194],\n",
      "       [  0, 195],\n",
      "       [  0, 196],\n",
      "       [  0, 197],\n",
      "       [  0, 198],\n",
      "       [  0, 199],\n",
      "       [  0, 200],\n",
      "       [  0, 201],\n",
      "       [  0, 202],\n",
      "       [  0, 203],\n",
      "       [  0, 204],\n",
      "       [  0, 205],\n",
      "       [  0, 206],\n",
      "       [  0, 207],\n",
      "       [  0, 208],\n",
      "       [  0, 209],\n",
      "       [  0, 210],\n",
      "       [  0, 211],\n",
      "       [  0, 212],\n",
      "       [  0, 213],\n",
      "       [  0, 214],\n",
      "       [  0, 215],\n",
      "       [  0, 216],\n",
      "       [  0, 217],\n",
      "       [  0, 218],\n",
      "       [  0, 219],\n",
      "       [  0, 220],\n",
      "       [  0, 221],\n",
      "       [  0, 222],\n",
      "       [  0, 223],\n",
      "       [  0, 224],\n",
      "       [  0, 225],\n",
      "       [  0, 226],\n",
      "       [  0, 227],\n",
      "       [  0, 228],\n",
      "       [  0, 229],\n",
      "       [  0, 230],\n",
      "       [  0, 231],\n",
      "       [  0, 232],\n",
      "       [  0, 233],\n",
      "       [  0, 234],\n",
      "       [  0, 235],\n",
      "       [  0, 236],\n",
      "       [  0, 237],\n",
      "       [  0, 238],\n",
      "       [  0, 239],\n",
      "       [  0, 240],\n",
      "       [  0, 241],\n",
      "       [  0, 242],\n",
      "       [  0, 243],\n",
      "       [  0, 244],\n",
      "       [  0, 245],\n",
      "       [  0, 246],\n",
      "       [  0, 247],\n",
      "       [  0, 248],\n",
      "       [  0, 249],\n",
      "       [  0, 250],\n",
      "       [  0, 251],\n",
      "       [  0, 252],\n",
      "       [  0, 253],\n",
      "       [  0, 254],\n",
      "       [  0, 255],\n",
      "       [  0, 256],\n",
      "       [  0, 257],\n",
      "       [  0, 258],\n",
      "       [  0, 259],\n",
      "       [  0, 260],\n",
      "       [  0, 261],\n",
      "       [  0, 262],\n",
      "       [  0, 263],\n",
      "       [  0, 264],\n",
      "       [  0, 265],\n",
      "       [  0, 266],\n",
      "       [  0, 267],\n",
      "       [  0, 268],\n",
      "       [  0, 269],\n",
      "       [  0, 270],\n",
      "       [  0, 271],\n",
      "       [  0, 272],\n",
      "       [  0, 273],\n",
      "       [  0, 274],\n",
      "       [  0, 275],\n",
      "       [  0, 276],\n",
      "       [  0, 277],\n",
      "       [  0, 278],\n",
      "       [  0, 279],\n",
      "       [  0, 280],\n",
      "       [  0, 281],\n",
      "       [  0, 282],\n",
      "       [  0, 283],\n",
      "       [  0, 284],\n",
      "       [  0, 285],\n",
      "       [  0, 286],\n",
      "       [  0, 287],\n",
      "       [  0, 288],\n",
      "       [  0, 289],\n",
      "       [  0, 290],\n",
      "       [  1,   0],\n",
      "       [  1,   1],\n",
      "       [  1,   2],\n",
      "       [  1,   3],\n",
      "       [  1,   4],\n",
      "       [  1,   5],\n",
      "       [  1,   6],\n",
      "       [  1,   7],\n",
      "       [  1,   8],\n",
      "       [  1,   9],\n",
      "       [  1,  10],\n",
      "       [  1,  11],\n",
      "       [  1,  12],\n",
      "       [  1,  13],\n",
      "       [  1,  14],\n",
      "       [  1,  15],\n",
      "       [  1,  16],\n",
      "       [  1,  17],\n",
      "       [  1,  18],\n",
      "       [  1,  19],\n",
      "       [  1,  20],\n",
      "       [  1,  21],\n",
      "       [  1,  22],\n",
      "       [  1,  23],\n",
      "       [  1,  24],\n",
      "       [  1,  25],\n",
      "       [  1,  26],\n",
      "       [  1,  27],\n",
      "       [  1,  28],\n",
      "       [  1,  29],\n",
      "       [  1,  30],\n",
      "       [  1,  31],\n",
      "       [  1,  32],\n",
      "       [  1,  33],\n",
      "       [  1,  34],\n",
      "       [  1,  35],\n",
      "       [  1,  36],\n",
      "       [  1,  37],\n",
      "       [  1,  38],\n",
      "       [  1,  39],\n",
      "       [  1,  40],\n",
      "       [  1,  41],\n",
      "       [  1,  42],\n",
      "       [  1,  43],\n",
      "       [  1,  44],\n",
      "       [  1,  45],\n",
      "       [  1,  46],\n",
      "       [  1,  47],\n",
      "       [  1,  48],\n",
      "       [  1,  49],\n",
      "       [  1,  50],\n",
      "       [  1,  51],\n",
      "       [  1,  52],\n",
      "       [  1,  53],\n",
      "       [  1,  54],\n",
      "       [  1,  55],\n",
      "       [  1,  56],\n",
      "       [  1,  57],\n",
      "       [  1,  58],\n",
      "       [  1,  59],\n",
      "       [  1,  60],\n",
      "       [  1,  61],\n",
      "       [  1,  62],\n",
      "       [  1,  63],\n",
      "       [  1,  64],\n",
      "       [  1,  65],\n",
      "       [  1,  66],\n",
      "       [  1,  67],\n",
      "       [  1,  68],\n",
      "       [  1,  69],\n",
      "       [  1,  70],\n",
      "       [  1,  71],\n",
      "       [  1,  72],\n",
      "       [  1,  73],\n",
      "       [  1,  74],\n",
      "       [  1,  75],\n",
      "       [  1,  76],\n",
      "       [  1,  77],\n",
      "       [  1,  78],\n",
      "       [  1,  79],\n",
      "       [  1,  80],\n",
      "       [  1,  81],\n",
      "       [  1,  82],\n",
      "       [  1,  83],\n",
      "       [  1,  84],\n",
      "       [  1,  85],\n",
      "       [  1,  86],\n",
      "       [  1,  87],\n",
      "       [  1,  88],\n",
      "       [  1,  89],\n",
      "       [  1,  90],\n",
      "       [  1,  91],\n",
      "       [  1,  92],\n",
      "       [  1,  93],\n",
      "       [  1,  94],\n",
      "       [  1,  95],\n",
      "       [  1,  96],\n",
      "       [  1,  97],\n",
      "       [  1,  98],\n",
      "       [  1,  99],\n",
      "       [  1, 100]]), values=array(['loinc:14959-1-295.828094-mg/g-n/a', 'loinc:55284-4-n/a-n/a-n/a',\n",
      "       'loinc:32465-7-n/a-n/a-n/a', 'loinc:2069-3-105.963943-mmol/L-n/a',\n",
      "       'loinc:2571-8-310.528625-mg/dL-n/a', 'loinc:4548-4-4.506774-%-n/a',\n",
      "       'loinc:29463-7-106.309120-kg-n/a', 'loinc:46288-7-n/a-n/a-n/a',\n",
      "       'loinc:2093-3-258.042786-mg/dL-n/a',\n",
      "       'loinc:8302-2-171.779221-cm-n/a',\n",
      "       'loinc:18262-6-156.787018-mg/dL-n/a',\n",
      "       'loinc:6299-2-9.123386-mg/dL-n/a',\n",
      "       'loinc:33914-3-22.366833-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2857-1-5.169333-ng/mL-n/a',\n",
      "       'loinc:2085-9-39.150036-mg/dL-n/a',\n",
      "       'loinc:2947-0-139.090652-mmol/L-n/a',\n",
      "       'loinc:2339-0-173.633896-mg/dL-n/a',\n",
      "       'loinc:49765-1-10.011961-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.495049-mmol/L-n/a',\n",
      "       'loinc:72514-3-3.557441-{score}-n/a',\n",
      "       'loinc:39156-5-36.027096-kg/m2-n/a',\n",
      "       'loinc:38483-4-4.951021-mg/dL-n/a', 'loinc:72166-2-n/a-n/a-n/a',\n",
      "       'loinc:20565-8-24.521408-mmol/L-n/a',\n",
      "       'loinc:72514-3-2.016495-{score}-n/a',\n",
      "       'loinc:14959-1-159.559586-mg/g-n/a',\n",
      "       'loinc:18262-6-168.837021-mg/dL-n/a',\n",
      "       'loinc:2069-3-109.438438-mmol/L-n/a',\n",
      "       'loinc:6299-2-10.390799-mg/dL-n/a',\n",
      "       'loinc:29463-7-105.264503-kg-n/a',\n",
      "       'loinc:38483-4-6.602094-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.762285-mmol/L-n/a',\n",
      "       'loinc:2093-3-239.646652-mg/dL-n/a',\n",
      "       'loinc:39156-5-35.673084-kg/m2-n/a', 'loinc:4548-4-4.418271-%-n/a',\n",
      "       'loinc:33914-3-16.387001-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2085-9-23.061338-mg/dL-n/a',\n",
      "       'loinc:20565-8-21.462990-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.498416-mg/dL-n/a',\n",
      "       'loinc:2339-0-138.187210-mg/dL-n/a',\n",
      "       'loinc:2947-0-140.278137-mmol/L-n/a',\n",
      "       'loinc:2571-8-238.741440-mg/dL-n/a',\n",
      "       'loinc:14959-1-242.760712-mg/g-n/a',\n",
      "       'loinc:6298-4-3.781971-mmol/L-n/a',\n",
      "       'loinc:2069-3-103.506561-mmol/L-n/a',\n",
      "       'loinc:2339-0-128.035172-mg/dL-n/a',\n",
      "       'loinc:2093-3-254.726227-mg/dL-n/a',\n",
      "       'loinc:33914-3-20.649792-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2085-9-28.638800-mg/dL-n/a',\n",
      "       'loinc:2947-0-142.502502-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.511320-mg/dL-n/a',\n",
      "       'loinc:2571-8-379.390167-mg/dL-n/a',\n",
      "       'loinc:20565-8-26.342453-mmol/L-n/a',\n",
      "       'loinc:38483-4-5.239206-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.109149-{score}-n/a',\n",
      "       'loinc:6299-2-10.638209-mg/dL-n/a',\n",
      "       'loinc:18262-6-150.209396-mg/dL-n/a',\n",
      "       'loinc:2947-0-143.648743-mmol/L-n/a',\n",
      "       'loinc:6299-2-9.595380-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.596942-mmol/L-n/a',\n",
      "       'loinc:2339-0-196.552582-mg/dL-n/a',\n",
      "       'loinc:2069-3-109.136337-mmol/L-n/a',\n",
      "       'loinc:14959-1-274.658691-mg/g-n/a',\n",
      "       'loinc:2085-9-27.038420-mg/dL-n/a',\n",
      "       'loinc:38483-4-4.094608-mg/dL-n/a',\n",
      "       'loinc:2093-3-242.790680-mg/dL-n/a',\n",
      "       'loinc:49765-1-9.266075-mg/dL-n/a',\n",
      "       'loinc:2571-8-335.246735-mg/dL-n/a',\n",
      "       'loinc:33914-3-26.422192-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:72514-3-1.381173-{score}-n/a',\n",
      "       'loinc:18262-6-148.702911-mg/dL-n/a',\n",
      "       'loinc:20565-8-20.081396-mmol/L-n/a',\n",
      "       'loinc:2857-1-5.761009-ng/mL-n/a',\n",
      "       'loinc:2085-9-31.737953-mg/dL-n/a',\n",
      "       'loinc:49765-1-8.553914-mg/dL-n/a',\n",
      "       'loinc:33914-3-20.647026-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:6299-2-14.115978-mg/dL-n/a',\n",
      "       'loinc:6298-4-5.033234-mmol/L-n/a',\n",
      "       'loinc:2093-3-242.147385-mg/dL-n/a',\n",
      "       'loinc:38483-4-5.239908-mg/dL-n/a',\n",
      "       'loinc:2947-0-142.735825-mmol/L-n/a',\n",
      "       'loinc:2339-0-135.517075-mg/dL-n/a',\n",
      "       'loinc:72514-3-2.683605-{score}-n/a',\n",
      "       'loinc:18262-6-138.491623-mg/dL-n/a',\n",
      "       'loinc:20565-8-22.980631-mmol/L-n/a',\n",
      "       'loinc:2069-3-105.157784-mmol/L-n/a',\n",
      "       'loinc:2571-8-359.589081-mg/dL-n/a',\n",
      "       'loinc:14959-1-47.750301-mg/g-n/a',\n",
      "       'loinc:2093-3-252.246872-mg/dL-n/a',\n",
      "       'loinc:2947-0-142.745697-mmol/L-n/a',\n",
      "       'loinc:20565-8-27.009485-mmol/L-n/a',\n",
      "       'loinc:2069-3-106.014923-mmol/L-n/a',\n",
      "       'loinc:2339-0-158.049500-mg/dL-n/a', 'loinc:4548-4-4.254275-%-n/a',\n",
      "       'loinc:38483-4-4.474086-mg/dL-n/a',\n",
      "       'loinc:2085-9-35.456039-mg/dL-n/a',\n",
      "       'loinc:72514-3-1.168931-{score}-n/a',\n",
      "       'loinc:49765-1-9.493873-mg/dL-n/a',\n",
      "       'loinc:6299-2-10.030460-mg/dL-n/a',\n",
      "       'loinc:2571-8-401.468201-mg/dL-n/a',\n",
      "       'loinc:33914-3-24.181143-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:6298-4-3.815404-mmol/L-n/a',\n",
      "       'loinc:18262-6-136.497192-mg/dL-n/a',\n",
      "       'loinc:14959-1-152.870224-mg/g-n/a',\n",
      "       'loinc:49765-1-8.739044-mg/dL-n/a',\n",
      "       'loinc:2571-8-331.133331-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.759748-mmol/L-n/a',\n",
      "       'loinc:33914-3-17.582542-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2085-9-22.290779-mg/dL-n/a',\n",
      "       'loinc:72514-3-0.982565-{score}-n/a',\n",
      "       'loinc:2069-3-104.051628-mmol/L-n/a',\n",
      "       'loinc:2093-3-249.273849-mg/dL-n/a',\n",
      "       'loinc:29463-7-103.328819-kg-n/a',\n",
      "       'loinc:14959-1-34.897572-mg/g-n/a',\n",
      "       'loinc:39156-5-35.017101-kg/m2-n/a',\n",
      "       'loinc:6299-2-10.285733-mg/dL-n/a',\n",
      "       'loinc:2947-0-140.045517-mmol/L-n/a',\n",
      "       'loinc:20565-8-20.823374-mmol/L-n/a',\n",
      "       'loinc:18262-6-160.756409-mg/dL-n/a',\n",
      "       'loinc:38483-4-5.958407-mg/dL-n/a',\n",
      "       'loinc:2339-0-162.309647-mg/dL-n/a',\n",
      "       'loinc:2085-9-32.619934-mg/dL-n/a',\n",
      "       'loinc:6298-4-5.044193-mmol/L-n/a',\n",
      "       'loinc:20565-8-27.899237-mmol/L-n/a',\n",
      "       'loinc:38483-4-4.245888-mg/dL-n/a',\n",
      "       'loinc:2571-8-464.373993-mg/dL-n/a',\n",
      "       'loinc:2947-0-141.385483-mmol/L-n/a',\n",
      "       'loinc:2857-1-1.517210-ng/mL-n/a',\n",
      "       'loinc:2069-3-103.315834-mmol/L-n/a',\n",
      "       'loinc:18262-6-118.970528-mg/dL-n/a',\n",
      "       'loinc:49765-1-10.102229-mg/dL-n/a',\n",
      "       'loinc:6299-2-7.741580-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.033964-{score}-n/a',\n",
      "       'loinc:2093-3-244.465256-mg/dL-n/a',\n",
      "       'loinc:14959-1-88.517120-mg/g-n/a',\n",
      "       'loinc:2339-0-159.659470-mg/dL-n/a',\n",
      "       'loinc:33914-3-24.674213-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:33914-3-21.965975-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:20565-8-26.755363-mmol/L-n/a',\n",
      "       'loinc:2571-8-254.369537-mg/dL-n/a',\n",
      "       'loinc:2069-3-103.991524-mmol/L-n/a',\n",
      "       'loinc:2339-0-176.233643-mg/dL-n/a',\n",
      "       'loinc:72514-3-1.962881-{score}-n/a',\n",
      "       'loinc:49765-1-8.575459-mg/dL-n/a',\n",
      "       'loinc:38483-4-4.769373-mg/dL-n/a',\n",
      "       'loinc:18262-6-156.591782-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.408529-mmol/L-n/a',\n",
      "       'loinc:2085-9-37.634701-mg/dL-n/a',\n",
      "       'loinc:2947-0-139.338730-mmol/L-n/a',\n",
      "       'loinc:6299-2-19.302988-mg/dL-n/a',\n",
      "       'loinc:2093-3-245.100388-mg/dL-n/a',\n",
      "       'loinc:14959-1-261.103333-mg/g-n/a',\n",
      "       'loinc:6690-2-9.436644-10*3/uL-n/a',\n",
      "       'loinc:2339-0-162.815613-mg/dL-n/a',\n",
      "       'loinc:29463-7-102.270058-kg-n/a',\n",
      "       'loinc:33914-3-28.367384-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:2093-3-249.265442-mg/dL-n/a',\n",
      "       'loinc:39156-5-34.658298-kg/m2-n/a',\n",
      "       'loinc:6299-2-15.234146-mg/dL-n/a',\n",
      "       'loinc:32623-1-10.390537-fL-n/a', 'loinc:718-7-15.890121-g/dL-n/a',\n",
      "       'loinc:787-2-91.570129-fL-n/a',\n",
      "       'loinc:777-3-175.475159-10*3/uL-n/a',\n",
      "       'loinc:2085-9-29.548708-mg/dL-n/a',\n",
      "       'loinc:2947-0-136.250412-mmol/L-n/a',\n",
      "       'loinc:786-4-34.731533-g/dL-n/a',\n",
      "       'loinc:6298-4-4.891128-mmol/L-n/a',\n",
      "       'loinc:21000-5-40.947231-fL-n/a',\n",
      "       'loinc:20565-8-27.904776-mmol/L-n/a',\n",
      "       'loinc:14959-1-35.104851-mg/g-n/a',\n",
      "       'loinc:38483-4-3.605199-mg/dL-n/a',\n",
      "       'loinc:49765-1-10.112781-mg/dL-n/a',\n",
      "       'loinc:18262-6-140.177658-mg/dL-n/a',\n",
      "       'loinc:4548-4-4.164575-%-n/a', 'loinc:785-6-31.107569-pg-n/a',\n",
      "       'loinc:2571-8-397.695343-mg/dL-n/a',\n",
      "       'loinc:789-8-4.008204-10*6/uL-n/a', 'loinc:4544-3-44.762665-%-n/a',\n",
      "       'loinc:32207-3-200.476288-fL-n/a',\n",
      "       'loinc:2069-3-107.128113-mmol/L-n/a',\n",
      "       'loinc:72514-3-2.095737-{score}-n/a',\n",
      "       'loinc:6298-4-4.957038-mmol/L-n/a',\n",
      "       'loinc:2069-3-108.926697-mmol/L-n/a',\n",
      "       'loinc:5804-0-374.061920-mg/dL-n/a', 'loinc:25428-4-n/a-n/a-n/a',\n",
      "       'loinc:1751-7-3.576444-g/dL-n/a',\n",
      "       'loinc:6299-2-14.192342-mg/dL-n/a',\n",
      "       'loinc:5792-7-0.971351-mg/dL-n/a',\n",
      "       'loinc:6690-2-4.608837-10*3/uL-n/a',\n",
      "       'loinc:5811-5-1.023260-{nominal}-n/a',\n",
      "       'loinc:786-4-34.066952-g/dL-n/a',\n",
      "       'loinc:20565-8-26.963699-mmol/L-n/a',\n",
      "       'loinc:21000-5-42.284977-fL-n/a',\n",
      "       'loinc:2093-3-252.204300-mg/dL-n/a',\n",
      "       'loinc:2947-0-136.581696-mmol/L-n/a',\n",
      "       'loinc:718-7-14.708368-g/dL-n/a', 'loinc:5803-2-6.355160-pH-n/a',\n",
      "       'loinc:2947-0-140.899033-mmol/L-n/a',\n",
      "       'loinc:18262-6-138.615753-mg/dL-n/a',\n",
      "       'loinc:72514-3-3.635177-{score}-n/a',\n",
      "       'loinc:6298-4-3.810878-mmol/L-n/a', 'loinc:5802-4-n/a-n/a-n/a',\n",
      "       'loinc:1742-6-46.340446-U/L-n/a',\n",
      "       'loinc:5797-6-0.907504-mg/dL-n/a', 'loinc:787-2-83.167702-fL-n/a',\n",
      "       'loinc:10834-0-2.371276-g/L-n/a',\n",
      "       'loinc:49765-1-9.633409-mg/dL-n/a', 'loinc:2514-8-n/a-n/a-n/a',\n",
      "       'loinc:32207-3-346.146942-fL-n/a',\n",
      "       'loinc:2085-9-35.159187-mg/dL-n/a',\n",
      "       'loinc:20565-8-21.034258-mmol/L-n/a',\n",
      "       'loinc:2339-0-167.573273-mg/dL-n/a',\n",
      "       'loinc:2885-2-63.490902-g/dL-n/a',\n",
      "       'loinc:6768-6-25.209621-U/L-n/a', 'loinc:785-6-29.997633-pg-n/a',\n",
      "       'loinc:777-3-199.146530-10*3/uL-n/a',\n",
      "       'loinc:1975-2-0.182355-mg/dL-n/a',\n",
      "       'loinc:38483-4-2.899073-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.995269-mg/dL-n/a',\n",
      "       'loinc:14959-1-273.078491-mg/g-n/a',\n",
      "       'loinc:2339-0-135.538223-mg/dL-n/a',\n",
      "       'loinc:2571-8-392.146759-mg/dL-n/a', 'loinc:32167-9-n/a-n/a-n/a',\n",
      "       'loinc:789-8-4.340217-10*6/uL-n/a', 'loinc:4544-3-49.098812-%-n/a',\n",
      "       'loinc:5770-3-n/a-n/a-n/a', 'loinc:20505-4-0.478789-mg/dL-n/a',\n",
      "       'loinc:33914-3-18.564865-mL/min-n/a', 'loinc:5799-2-n/a-n/a-n/a',\n",
      "       'loinc:33914-3-25.597788-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:49765-1-9.726962-mg/dL-n/a', 'loinc:5778-6-n/a-n/a-n/a',\n",
      "       'loinc:1920-8-39.088749-U/L-n/a',\n",
      "       'loinc:2857-1-7.599798-ng/mL-n/a',\n",
      "       'loinc:2069-3-105.630051-mmol/L-n/a', 'loinc:5794-3-n/a-n/a-n/a',\n",
      "       'loinc:32623-1-11.156581-fL-n/a',\n",
      "       'loinc:6299-2-18.711081-mg/dL-n/a', 'loinc:5767-9-n/a-n/a-n/a',\n",
      "       'loinc:20454-5-n/a-n/a-n/a', 'loinc:2093-3-252.340820-mg/dL-n/a',\n",
      "       'loinc:2085-9-26.215549-mg/dL-n/a',\n",
      "       'loinc:2339-0-162.977448-mg/dL-n/a',\n",
      "       'loinc:2947-0-140.868454-mmol/L-n/a',\n",
      "       'loinc:14959-1-224.270645-mg/g-n/a',\n",
      "       'loinc:6299-2-7.388378-mg/dL-n/a',\n",
      "       'loinc:29463-7-100.707916-kg-n/a',\n",
      "       'loinc:18262-6-143.162643-mg/dL-n/a',\n",
      "       'loinc:2069-3-105.315552-mmol/L-n/a',\n",
      "       'loinc:33914-3-15.438135-mL/min/{1.73_m2}-n/a',\n",
      "       'loinc:39156-5-34.128902-kg/m2-n/a',\n",
      "       'loinc:72514-3-0.159420-{score}-n/a',\n",
      "       'loinc:38483-4-6.432720-mg/dL-n/a',\n",
      "       'loinc:20565-8-27.974821-mmol/L-n/a',\n",
      "       'loinc:4548-4-4.032226-%-n/a', 'loinc:49765-1-8.920292-mg/dL-n/a',\n",
      "       'loinc:2571-8-414.813141-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.477590-mmol/L-n/a',\n",
      "       'loinc:6298-4-5.038575-mmol/L-n/a', 'loinc:785-6-32.722614-pg-n/a',\n",
      "       'loinc:2339-0-193.423340-mg/dL-n/a',\n",
      "       'loinc:10834-0-3.290043-g/L-n/a', 'loinc:5803-2-6.972992-pH-n/a',\n",
      "       'loinc:1742-6-47.472557-U/L-n/a',\n",
      "       'loinc:6299-2-11.910412-mg/dL-n/a',\n",
      "       'loinc:2947-0-137.538879-mmol/L-n/a',\n",
      "       'loinc:787-2-81.473427-fL-n/a', 'loinc:1975-2-0.564079-mg/dL-n/a',\n",
      "       'loinc:32207-3-500.708557-fL-n/a',\n",
      "       'loinc:786-4-35.881981-g/dL-n/a',\n",
      "       'loinc:20505-4-0.681995-mg/dL-n/a',\n",
      "       'loinc:32623-1-9.531248-fL-n/a', 'loinc:21000-5-44.570206-fL-n/a',\n",
      "       'loinc:5804-0-396.220978-mg/dL-n/a',\n",
      "       'loinc:5797-6-1.491175-mg/dL-n/a',\n",
      "       'loinc:2069-3-108.874191-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.614595-mg/dL-n/a',\n",
      "       'loinc:789-8-4.218841-10*6/uL-n/a',\n",
      "       'loinc:33914-3-14.302351-mL/min-n/a',\n",
      "       'loinc:6768-6-75.041794-U/L-n/a',\n",
      "       'loinc:6690-2-3.140338-10*3/uL-n/a',\n",
      "       'loinc:38483-4-2.555436-mg/dL-n/a',\n",
      "       'loinc:777-3-221.783173-10*3/uL-n/a',\n",
      "       'loinc:5792-7-1.515693-mg/dL-n/a',\n",
      "       'loinc:20565-8-21.010006-mmol/L-n/a',\n",
      "       'loinc:718-7-15.122309-g/dL-n/a',\n",
      "       'loinc:2885-2-69.579010-g/dL-n/a', 'loinc:1920-8-9.376979-U/L-n/a',\n",
      "       'loinc:5811-5-1.011210-{nominal}-n/a',\n",
      "       'loinc:1751-7-4.339825-g/dL-n/a', 'loinc:4544-3-47.453426-%-n/a',\n",
      "       'loinc:49765-1-9.514345-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.061561-mmol/L-n/a',\n",
      "       'loinc:2571-8-112.808517-mg/dL-n/a',\n",
      "       'loinc:2947-0-143.689316-mmol/L-n/a',\n",
      "       'loinc:38483-4-2.661478-mg/dL-n/a',\n",
      "       'loinc:20565-8-28.679024-mmol/L-n/a',\n",
      "       'loinc:1975-2-0.953996-mg/dL-n/a',\n",
      "       'loinc:1920-8-17.169775-U/L-n/a',\n",
      "       'loinc:33914-3-71.272980-mL/min-n/a',\n",
      "       'loinc:6768-6-113.534615-U/L-n/a',\n",
      "       'loinc:2339-0-94.018082-mg/dL-n/a',\n",
      "       'loinc:1751-7-5.038779-g/dL-n/a', 'loinc:1742-6-42.081043-U/L-n/a',\n",
      "       'loinc:10834-0-2.482501-g/L-n/a',\n",
      "       'loinc:6299-2-16.587158-mg/dL-n/a',\n",
      "       'loinc:2085-9-57.907360-mg/dL-n/a',\n",
      "       'loinc:18262-6-85.270325-mg/dL-n/a',\n",
      "       'loinc:2093-3-189.180573-mg/dL-n/a',\n",
      "       'loinc:2885-2-67.320488-g/dL-n/a',\n",
      "       'loinc:2069-3-106.530792-mmol/L-n/a',\n",
      "       'loinc:2857-1-0.603180-ng/mL-n/a', 'loinc:55284-4-n/a-n/a-n/a',\n",
      "       'loinc:72514-3-0.207440-{score}-n/a', 'loinc:72166-2-n/a-n/a-n/a',\n",
      "       'loinc:8302-2-180.266525-cm-n/a',\n",
      "       'loinc:39156-5-27.829773-kg/m2-n/a', 'loinc:32465-7-n/a-n/a-n/a',\n",
      "       'loinc:29463-7-90.435684-kg-n/a',\n",
      "       'loinc:2571-8-172.159851-mg/dL-n/a',\n",
      "       'loinc:2885-2-76.901802-g/dL-n/a',\n",
      "       'loinc:38483-4-2.931739-mg/dL-n/a',\n",
      "       'loinc:1975-2-0.301103-mg/dL-n/a',\n",
      "       'loinc:2069-3-104.201447-mmol/L-n/a',\n",
      "       'loinc:2085-9-44.840656-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.181541-mmol/L-n/a',\n",
      "       'loinc:1742-6-52.676575-U/L-n/a',\n",
      "       'loinc:6299-2-8.311484-mg/dL-n/a',\n",
      "       'loinc:33914-3-86.380386-mL/min-n/a',\n",
      "       'loinc:20565-8-25.926813-mmol/L-n/a',\n",
      "       'loinc:10834-0-2.640645-g/L-n/a',\n",
      "       'loinc:2093-3-165.216064-mg/dL-n/a',\n",
      "       'loinc:2339-0-75.633041-mg/dL-n/a',\n",
      "       'loinc:1920-8-33.820660-U/L-n/a',\n",
      "       'loinc:2947-0-139.872971-mmol/L-n/a',\n",
      "       'loinc:49765-1-9.338635-mg/dL-n/a',\n",
      "       'loinc:18262-6-106.437988-mg/dL-n/a',\n",
      "       'loinc:6768-6-68.069191-U/L-n/a', 'loinc:1751-7-4.309004-g/dL-n/a',\n",
      "       'loinc:2857-1-2.448312-ng/mL-n/a',\n",
      "       'loinc:39156-5-27.416416-kg/m2-n/a',\n",
      "       'loinc:29463-7-89.092438-kg-n/a',\n",
      "       'loinc:72514-3-2.929030-{score}-n/a',\n",
      "       'loinc:2339-0-71.014603-mg/dL-n/a',\n",
      "       'loinc:6299-2-8.192121-mg/dL-n/a',\n",
      "       'loinc:1975-2-1.136997-mg/dL-n/a',\n",
      "       'loinc:6298-4-4.720258-mmol/L-n/a',\n",
      "       'loinc:2885-2-78.614975-g/dL-n/a',\n",
      "       'loinc:2093-3-186.944519-mg/dL-n/a',\n",
      "       'loinc:38483-4-2.954107-mg/dL-n/a',\n",
      "       'loinc:1751-7-5.180547-g/dL-n/a',\n",
      "       'loinc:2571-8-134.744431-mg/dL-n/a',\n",
      "       'loinc:6768-6-107.203194-U/L-n/a', 'loinc:1920-8-6.237681-U/L-n/a',\n",
      "       'loinc:33914-3-85.869530-mL/min-n/a',\n",
      "       'loinc:10834-0-2.592540-g/L-n/a',\n",
      "       'loinc:49765-1-8.574694-mg/dL-n/a',\n",
      "       'loinc:20565-8-28.610134-mmol/L-n/a',\n",
      "       'loinc:2069-3-110.476578-mmol/L-n/a',\n",
      "       'loinc:2085-9-42.903580-mg/dL-n/a',\n",
      "       'loinc:1742-6-58.486881-U/L-n/a',\n",
      "       'loinc:18262-6-91.319489-mg/dL-n/a',\n",
      "       'loinc:2947-0-140.001114-mmol/L-n/a',\n",
      "       'loinc:2571-8-107.013672-mg/dL-n/a',\n",
      "       'loinc:39156-5-27.048056-kg/m2-n/a',\n",
      "       'loinc:29463-7-87.895409-kg-n/a',\n",
      "       'loinc:72514-3-1.980485-{score}-n/a',\n",
      "       'loinc:2085-9-77.743858-mg/dL-n/a',\n",
      "       'loinc:2857-1-7.265638-ng/mL-n/a', 'loinc:46288-7-n/a-n/a-n/a',\n",
      "       'loinc:18262-6-92.092575-mg/dL-n/a',\n",
      "       'loinc:2093-3-191.239166-mg/dL-n/a',\n",
      "       'loinc:38483-4-3.394849-mg/dL-n/a',\n",
      "       'loinc:10834-0-3.175749-g/L-n/a', 'loinc:1742-6-52.713997-U/L-n/a',\n",
      "       'loinc:6768-6-90.502106-U/L-n/a',\n",
      "       'loinc:2571-8-108.978813-mg/dL-n/a',\n",
      "       'loinc:2085-9-40.924133-mg/dL-n/a',\n",
      "       'loinc:6299-2-10.904804-mg/dL-n/a',\n",
      "       'loinc:2093-3-192.639542-mg/dL-n/a',\n",
      "       'loinc:2069-3-104.763016-mmol/L-n/a',\n",
      "       'loinc:2885-2-77.366127-g/dL-n/a',\n",
      "       'loinc:1975-2-0.756571-mg/dL-n/a',\n",
      "       'loinc:18262-6-147.474869-mg/dL-n/a',\n",
      "       'loinc:1751-7-5.433212-g/dL-n/a',\n",
      "       'loinc:6298-4-3.753698-mmol/L-n/a',\n",
      "       'loinc:20565-8-25.247972-mmol/L-n/a',\n",
      "       'loinc:1920-8-29.142744-U/L-n/a',\n",
      "       'loinc:2339-0-91.252815-mg/dL-n/a',\n",
      "       'loinc:2947-0-142.470612-mmol/L-n/a',\n",
      "       'loinc:33914-3-76.652672-mL/min-n/a',\n",
      "       'loinc:49765-1-9.170337-mg/dL-n/a'], dtype=object), dense_shape=array([  2, 291])), 's-Condition.code-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.reason.hcc-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.hospitalization.admitSource-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Procedure.code.cpt-til-2592000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.hospitalization.admitSource-til-31536000': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.type-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-MedicationRequest.contained.medication.code.gsn-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Procedure.code.cpt-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Procedure.code.cpt-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 'c-Patient.gender': SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0]]), values=array(['male', 'male'], dtype=object), dense_shape=array([2, 1])), 's-Composition.section.text.div.tokenized-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Encounter.hospitalization.admitSource-til-86400': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0])), 's-Composition.type-til-604800': SparseTensorValue(indices=array([], shape=(0, 2), dtype=int64), values=array([], dtype=object), dense_shape=array([2, 0]))}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#train_file = path + 'train'\n",
    "#validation_file = path + 'validation'\n",
    "hparams = create_hparams()\n",
    "\n",
    "time_crossed_features = [\n",
    "        cross.split(':') for cross in hparams.time_crossed_features if cross\n",
    "    ]\n",
    "\n",
    "map_, label_ = get_input_fn(tf.estimator.ModeKeys.TRAIN, train_file, True, hparams.time_windows,\n",
    "                            hparams.include_age, hparams.categorical_context_features,\n",
    "                            hparams.sequence_features, time_crossed_features, batch_size=2)()\n",
    "with tf.train.MonitoredSession() as sess:\n",
    "  map_['label'] = label_\n",
    "  print(sess.run(map_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f63f54882d0>, '_model_dir': '/tmp/models/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "seq_features = []\n",
    "seq_features_sizes = []\n",
    "hparams = create_hparams()\n",
    "\n",
    "for k, bucket_size in zip(\n",
    "    hparams.sequence_features,\n",
    "    hparams.sequence_bucket_sizes):\n",
    "  for max_age in hparams.time_windows[1:]:\n",
    "    seq_features.append(\n",
    "        tf.feature_column.categorical_column_with_hash_bucket(\n",
    "            SEQUENCE_KEY_PREFIX + k + '-til-' +\n",
    "            str(max_age), bucket_size))\n",
    "    seq_features_sizes.append(bucket_size)\n",
    "\n",
    "categorical_context_features = [\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        CONTEXT_KEY_PREFIX + k, bucket_size)\n",
    "    for k, bucket_size in zip(hparams.categorical_context_features,\n",
    "                              hparams.context_bucket_sizes)\n",
    "]\n",
    "discretized_context_features = []\n",
    "if hparams.include_age:\n",
    "  discretized_context_features.append(\n",
    "      tf.feature_column.bucketized_column(\n",
    "          tf.feature_column.numeric_column(CONTEXT_KEY_PREFIX + AGE_KEY),\n",
    "          boundaries=hparams.age_boundaries))\n",
    "\n",
    "optimizer = tf.train.FtrlOptimizer(\n",
    "      learning_rate=hparams.learning_rate,\n",
    "      l1_regularization_strength=hparams.l1_regularization_strength,\n",
    "      l2_regularization_strength=hparams.l2_regularization_strength)\n",
    "\n",
    "estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=seq_features + categorical_context_features +\n",
    "    discretized_context_features,\n",
    "    n_classes=len(LABEL_VALUES),\n",
    "    label_vocabulary=LABEL_VALUES,\n",
    "    model_dir=output_dir,\n",
    "    optimizer=optimizer,\n",
    "    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f63f556bed0>, '_model_dir': '/tmp/models/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "def multiclass_metrics_fn(labels, predictions):\n",
    "  \"\"\"Computes precsion/recall@k metrics for each class and micro-weighted.\n",
    "\n",
    "  Args:\n",
    "    labels: A string Tensor of shape [batch_size] with the true labels\n",
    "    predictions: A float Tensor of shape [batch_size, num_classes].\n",
    "\n",
    "  Returns:\n",
    "    A dictionary with metrics of precision/recall @1/2 and precision/recall per\n",
    "    class.\n",
    "  \"\"\"\n",
    "\n",
    "  label_ids = tf.contrib.lookup.index_table_from_tensor(\n",
    "      tuple(LABEL_VALUES),\n",
    "      name='class_id_lookup').lookup(labels)\n",
    "  dense_labels = tf.one_hot(label_ids, len(LABEL_VALUES))\n",
    "\n",
    "  # We convert the task to a binary one of < 7 days.\n",
    "  # 'less_or_equal_3', '3_7', '7_14', 'above_14'\n",
    "  binary_labels = label_ids < 2\n",
    "  binary_probs = tf.reduce_sum(predictions['probabilities'][:, 0:2], axis=1)\n",
    "\n",
    "  metrics_dict = {\n",
    "      'precision_at_1':\n",
    "          tf.metrics.precision_at_k(\n",
    "              labels=label_ids,\n",
    "              predictions=predictions['probabilities'], k=1),\n",
    "      'precision_at_2':\n",
    "          tf.metrics.precision_at_k(\n",
    "              labels=label_ids,\n",
    "              predictions=predictions['probabilities'], k=2),\n",
    "      'recall_at_1':\n",
    "          tf.metrics.recall_at_k(\n",
    "              labels=label_ids,\n",
    "              predictions=predictions['probabilities'], k=1),\n",
    "      'recall_at_2':\n",
    "          tf.metrics.recall_at_k(\n",
    "              labels=label_ids,\n",
    "              predictions=predictions['probabilities'], k=2),\n",
    "      'auc_roc_at_most_7d':\n",
    "          tf.metrics.auc(\n",
    "              labels=binary_labels,\n",
    "              predictions=binary_probs,\n",
    "              curve='ROC',\n",
    "              summation_method='careful_interpolation'),\n",
    "      'auc_pr_at_most_7d':\n",
    "          tf.metrics.auc(\n",
    "              labels=binary_labels,\n",
    "              predictions=binary_probs,\n",
    "              curve='PR',\n",
    "              summation_method='careful_interpolation'),\n",
    "      'precision_at_most_7d':\n",
    "          tf.metrics.precision(\n",
    "              labels=binary_labels,\n",
    "              predictions=binary_probs >= 0.5),\n",
    "      'recall_at_most_7d':\n",
    "          tf.metrics.recall(\n",
    "              labels=binary_labels,\n",
    "              predictions=binary_probs >= 0.5),\n",
    "  }\n",
    "  for i, label in enumerate(LABEL_VALUES):\n",
    "    metrics_dict['precision_%s' % label] = tf.metrics.precision_at_k(\n",
    "        labels=label_ids,\n",
    "        predictions=predictions['probabilities'],\n",
    "        k=1,\n",
    "        class_id=i)\n",
    "    metrics_dict['recall_%s' % label] = tf.metrics.recall_at_k(\n",
    "        labels=label_ids,\n",
    "        predictions=predictions['probabilities'],\n",
    "        k=1,\n",
    "        class_id=i)\n",
    "\n",
    "  return metrics_dict\n",
    "estimator = tf.contrib.estimator.add_metrics(estimator, multiclass_metrics_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(tf.estimator.ModeKeys.TRAIN, train_file, True, hparams.time_windows,\n",
    "                            hparams.include_age, hparams.categorical_context_features,\n",
    "                            hparams.sequence_features, time_crossed_features, batch_size=24)\n",
    "validation_input_fn = get_input_fn(tf.estimator.ModeKeys.EVAL, validation_file, True, hparams.time_windows,\n",
    "                            hparams.include_age, hparams.categorical_context_features,\n",
    "                            hparams.sequence_features, time_crossed_features, batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/models/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.441306, step = 101\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /tmp/models/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.32748.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-09-17:43:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [4/40]\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-09-17:43:42\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.46575344, auc_pr_at_most_7d = 1.0, auc_roc_at_most_7d = 0.0, average_loss = 1.3059196, global_step = 200, loss = 1.3090744, precision_3_7 = nan, precision_7_14 = nan, precision_above_14 = 0.0, precision_at_1 = 0.4657534246575342, precision_at_2 = 0.4726027397260274, precision_at_most_7d = 1.0, precision_less_or_equal_3 = 0.918918918918919, recall_3_7 = 0.0, recall_7_14 = nan, recall_above_14 = nan, recall_at_1 = 0.4657534246575342, recall_at_2 = 0.9452054794520548, recall_at_most_7d = 0.5068493, recall_less_or_equal_3 = 0.4927536231884058\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: /tmp/models/model.ckpt-200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.46575344,\n",
       " 'auc_pr_at_most_7d': 1.0,\n",
       " 'auc_roc_at_most_7d': 0.0,\n",
       " 'average_loss': 1.3059196,\n",
       " 'global_step': 200,\n",
       " 'loss': 1.3090744,\n",
       " 'precision_3_7': nan,\n",
       " 'precision_7_14': nan,\n",
       " 'precision_above_14': 0.0,\n",
       " 'precision_at_1': 0.4657534246575342,\n",
       " 'precision_at_2': 0.4726027397260274,\n",
       " 'precision_at_most_7d': 1.0,\n",
       " 'precision_less_or_equal_3': 0.918918918918919,\n",
       " 'recall_3_7': 0.0,\n",
       " 'recall_7_14': nan,\n",
       " 'recall_above_14': nan,\n",
       " 'recall_at_1': 0.4657534246575342,\n",
       " 'recall_at_2': 0.9452054794520548,\n",
       " 'recall_at_most_7d': 0.5068493,\n",
       " 'recall_less_or_equal_3': 0.4927536231884058}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, steps=100)\n",
    "estimator.evaluate(input_fn=validation_input_fn, steps=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
