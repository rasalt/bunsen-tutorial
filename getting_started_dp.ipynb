{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook loads a collection of synthetic FHIR bundles and value sets and shows some simple queries. Running this first will set up the environment for other notebooks in the tutorial\n",
    "\n",
    "## Setup Tasks\n",
    "Some setup before the real show begins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Enable Hive support for our session so we can save resources as Hive tables\n",
    "spark = SparkSession.builder \\\n",
    "                    .config('hive.exec.dynamic.partition.mode', 'nonstrict') \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Synthetic Data\n",
    "This tutorial uses data generated by Synthea. It is simply a directory of STU3 bundles visible included in the tutorial; you can see it in the bundles directory.\n",
    "\n",
    "Let's load the bundles and examine a couple data types in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bunsen.stu3.bundles import load_from_directory, extract_entry, write_to_database\n",
    "\n",
    "# Load and cache the bundles so we don't reload them every time.\n",
    "bundles = load_from_directory(spark, 'gs://bunsen/data/bundles').cache()\n",
    "\n",
    "# Get the observation and encounters\n",
    "observations = extract_entry(spark, bundles, 'observation')\n",
    "encounters = extract_entry(spark, bundles, 'encounter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bunsen documentation\n",
    "To get help using functions like *load_from_directory* or *extract_entry*, you can see the documentation at https://engineering.cerner.com/bunsen or via Python's help system, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function extract_entry in module bunsen.stu3.bundles:\n",
      "\n",
      "extract_entry(sparkSession, javaRDD, resourceName)\n",
      "    Returns a dataset for the given entry type from the bundles.\n",
      "    \n",
      "    :param sparkSession: the SparkSession instance\n",
      "    :param javaRDD: the RDD produced by :func:`load_from_directory` or other methods\n",
      "        in this package\n",
      "    :param resourceName: the name of the FHIR resource to extract\n",
      "        (condition, observation, etc)\n",
      "    :return: a DataFrame containing the given resource encoded into Spark columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(extract_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- versionId: string (nullable = true)\n",
      " |    |-- lastUpdated: timestamp (nullable = true)\n",
      " |    |-- profile: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- security: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- tag: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |-- implicitRules: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- text: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- div: string (nullable = true)\n",
      " |-- identifier: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- use: string (nullable = true)\n",
      " |    |    |-- type: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |    |    |-- period: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- start: string (nullable = true)\n",
      " |    |    |    |-- end: string (nullable = true)\n",
      " |    |    |-- assigner: struct (nullable = true)\n",
      " |    |    |    |-- reference: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |-- basedOn: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- reference: string (nullable = true)\n",
      " |    |    |-- display: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- code: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- subject: struct (nullable = true)\n",
      " |    |-- reference: string (nullable = true)\n",
      " |    |-- display: string (nullable = true)\n",
      " |-- context: struct (nullable = true)\n",
      " |    |-- reference: string (nullable = true)\n",
      " |    |-- display: string (nullable = true)\n",
      " |-- effectivePeriod: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- start: string (nullable = true)\n",
      " |    |-- end: string (nullable = true)\n",
      " |-- effectiveDateTime: string (nullable = true)\n",
      " |-- issued: timestamp (nullable = true)\n",
      " |-- performer: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- reference: string (nullable = true)\n",
      " |    |    |-- display: string (nullable = true)\n",
      " |-- valueBoolean: boolean (nullable = true)\n",
      " |-- valuePeriod: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- start: string (nullable = true)\n",
      " |    |-- end: string (nullable = true)\n",
      " |-- valueSampledData: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- origin: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |-- unit: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |-- period: decimal(12,4) (nullable = true)\n",
      " |    |-- factor: decimal(12,4) (nullable = true)\n",
      " |    |-- lowerLimit: decimal(12,4) (nullable = true)\n",
      " |    |-- upperLimit: decimal(12,4) (nullable = true)\n",
      " |    |-- dimensions: integer (nullable = true)\n",
      " |    |-- data: string (nullable = true)\n",
      " |-- valueRatio: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- numerator: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |-- unit: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |-- denominator: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |-- unit: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |-- valueRange: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- low: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |-- unit: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |-- high: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |-- unit: string (nullable = true)\n",
      " |    |    |-- system: string (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |-- valueTime: string (nullable = true)\n",
      " |-- valueDateTime: string (nullable = true)\n",
      " |-- valueQuantity: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |-- comparator: string (nullable = true)\n",
      " |    |-- unit: string (nullable = true)\n",
      " |    |-- system: string (nullable = true)\n",
      " |    |-- code: string (nullable = true)\n",
      " |-- valueCodeableConcept: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- valueString: string (nullable = true)\n",
      " |-- valueAttachment: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- contentType: string (nullable = true)\n",
      " |    |-- language: string (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- size: integer (nullable = true)\n",
      " |    |-- hash: binary (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- creation: string (nullable = true)\n",
      " |-- dataAbsentReason: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- interpretation: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- bodySite: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- method: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- coding: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- specimen: struct (nullable = true)\n",
      " |    |-- reference: string (nullable = true)\n",
      " |    |-- display: string (nullable = true)\n",
      " |-- device: struct (nullable = true)\n",
      " |    |-- reference: string (nullable = true)\n",
      " |    |-- display: string (nullable = true)\n",
      " |-- referenceRange: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- low: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- high: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- type: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- appliesTo: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- age: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- low: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- high: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- related: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- target: struct (nullable = true)\n",
      " |    |    |    |-- reference: string (nullable = true)\n",
      " |    |    |    |-- display: string (nullable = true)\n",
      " |-- component: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- code: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- valuePeriod: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- start: string (nullable = true)\n",
      " |    |    |    |-- end: string (nullable = true)\n",
      " |    |    |-- valueSampledData: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- origin: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- period: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- factor: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- lowerLimit: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- upperLimit: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- dimensions: integer (nullable = true)\n",
      " |    |    |    |-- data: string (nullable = true)\n",
      " |    |    |-- valueRatio: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- numerator: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- denominator: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- valueRange: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- low: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |-- high: struct (nullable = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- valueTime: string (nullable = true)\n",
      " |    |    |-- valueDateTime: string (nullable = true)\n",
      " |    |    |-- valueQuantity: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- valueCodeableConcept: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- valueString: string (nullable = true)\n",
      " |    |    |-- valueAttachment: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- contentType: string (nullable = true)\n",
      " |    |    |    |-- language: string (nullable = true)\n",
      " |    |    |    |-- data: binary (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- size: integer (nullable = true)\n",
      " |    |    |    |-- hash: binary (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- creation: string (nullable = true)\n",
      " |    |    |-- dataAbsentReason: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- interpretation: struct (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- referenceRange: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |-- low: struct (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |-- high: struct (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |-- type: struct (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |-- appliesTo: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- coding: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- version: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- display: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- userSelected: boolean (nullable = true)\n",
      " |    |    |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |-- age: struct (nullable = true)\n",
      " |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |-- low: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |    |-- high: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- value: decimal(12,4) (nullable = true)\n",
      " |    |    |    |    |    |    |-- comparator: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- system: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- code: string (nullable = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observations.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some data\n",
    "The next step will load some data and inspect it. Since Spark lazily delays execution until output is needed, all of the work will be done here. This can take several seconds or longer depending on the machine, but users can check its status by looking at the [Spark application page](http://localhost:4040).\n",
    "\n",
    "For now, let's just turn our encounter resources into a simple table of all encounters since 2013:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>code</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>2013-01-31T00:59:02-06:00</td>\n",
       "      <td>2013-01-31T00:59:02-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>ambulatory</td>\n",
       "      <td>2015-09-15T01:59:02-05:00</td>\n",
       "      <td>2015-09-15T01:59:02-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>2016-02-04T00:59:02-06:00</td>\n",
       "      <td>2016-02-04T00:59:02-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>ambulatory</td>\n",
       "      <td>2016-04-19T01:59:02-05:00</td>\n",
       "      <td>2016-04-19T01:59:02-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>emergency</td>\n",
       "      <td>2018-01-04T00:59:02-06:00</td>\n",
       "      <td>2018-01-04T00:59:02-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>ambulatory</td>\n",
       "      <td>2013-01-04T21:59:31-06:00</td>\n",
       "      <td>2013-01-04T21:59:31-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>ambulatory</td>\n",
       "      <td>2013-01-11T21:59:31-06:00</td>\n",
       "      <td>2013-01-11T22:14:31-06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>ambulatory</td>\n",
       "      <td>2013-03-22T22:59:31-05:00</td>\n",
       "      <td>2013-03-22T23:14:31-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>2013-09-27T22:59:31-05:00</td>\n",
       "      <td>2013-09-27T22:59:31-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>2014-10-03T22:59:31-05:00</td>\n",
       "      <td>2014-10-03T22:59:31-05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reference        code  \\\n",
       "0  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b    WELLNESS   \n",
       "1  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  ambulatory   \n",
       "2  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b    WELLNESS   \n",
       "3  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  ambulatory   \n",
       "4  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b   emergency   \n",
       "5  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18  ambulatory   \n",
       "6  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18  ambulatory   \n",
       "7  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18  ambulatory   \n",
       "8  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18    WELLNESS   \n",
       "9  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18    WELLNESS   \n",
       "\n",
       "                       start                        end  \n",
       "0  2013-01-31T00:59:02-06:00  2013-01-31T00:59:02-06:00  \n",
       "1  2015-09-15T01:59:02-05:00  2015-09-15T01:59:02-05:00  \n",
       "2  2016-02-04T00:59:02-06:00  2016-02-04T00:59:02-06:00  \n",
       "3  2016-04-19T01:59:02-05:00  2016-04-19T01:59:02-05:00  \n",
       "4  2018-01-04T00:59:02-06:00  2018-01-04T00:59:02-06:00  \n",
       "5  2013-01-04T21:59:31-06:00  2013-01-04T21:59:31-06:00  \n",
       "6  2013-01-11T21:59:31-06:00  2013-01-11T22:14:31-06:00  \n",
       "7  2013-03-22T22:59:31-05:00  2013-03-22T23:14:31-05:00  \n",
       "8  2013-09-27T22:59:31-05:00  2013-09-27T22:59:31-05:00  \n",
       "9  2014-10-03T22:59:31-05:00  2014-10-03T22:59:31-05:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "encounters.select('subject.reference', \n",
    "                  'class.code', \n",
    "                  'period.start', \n",
    "                  'period.end') \\\n",
    "          .where(col('start') > '2013') \\\n",
    "          .limit(10) \\\n",
    "          .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploding nested lists\n",
    "FHIR's nested structures group related data, making many workloads simpler. We can reference such nested structures directly, and \"explode\" nested lists when needed to analyze them. Let's build a table of all observation codes in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>system</th>\n",
       "      <th>code</th>\n",
       "      <th>display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>8331-1</td>\n",
       "      <td>Oral temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>8302-2</td>\n",
       "      <td>Body Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>29463-7</td>\n",
       "      <td>Body Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>39156-5</td>\n",
       "      <td>Body Mass Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>55284-4</td>\n",
       "      <td>Blood Pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>8302-2</td>\n",
       "      <td>Body Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>29463-7</td>\n",
       "      <td>Body Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>39156-5</td>\n",
       "      <td>Body Mass Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>55284-4</td>\n",
       "      <td>Blood Pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b</td>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>4548-4</td>\n",
       "      <td>Hemoglobin A1c/Hemoglobin.total in Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reference            system     code  \\\n",
       "0  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org   8331-1   \n",
       "1  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org   8302-2   \n",
       "2  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  29463-7   \n",
       "3  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  39156-5   \n",
       "4  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  55284-4   \n",
       "5  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org   8302-2   \n",
       "6  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  29463-7   \n",
       "7  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  39156-5   \n",
       "8  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org  55284-4   \n",
       "9  urn:uuid:214ff775-6924-4ecf-aedd-9847146fe66b  http://loinc.org   4548-4   \n",
       "\n",
       "                                    display  \n",
       "0                          Oral temperature  \n",
       "1                               Body Height  \n",
       "2                               Body Weight  \n",
       "3                           Body Mass Index  \n",
       "4                            Blood Pressure  \n",
       "5                               Body Height  \n",
       "6                               Body Weight  \n",
       "7                           Body Mass Index  \n",
       "8                            Blood Pressure  \n",
       "9  Hemoglobin A1c/Hemoglobin.total in Blood  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "codes = observations.select('subject',\n",
    "                            explode('code.coding').alias('coding')) \\\n",
    "                    .select('subject.reference', \n",
    "                            'coding.system', \n",
    "                            'coding.code',\n",
    "                            'coding.display')\n",
    "                    \n",
    "codes.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing data\n",
    "Our datasets become much easier to analyze once they've been projected onto a simpler model that suits the problem at hand. The code below simply shows the most frequent observation codes in our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>code</th>\n",
       "      <th>display</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>4548-4</td>\n",
       "      <td>Hemoglobin A1c/Hemoglobin.total in Blood</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>8302-2</td>\n",
       "      <td>Body Height</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>55284-4</td>\n",
       "      <td>Blood Pressure</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>29463-7</td>\n",
       "      <td>Body Weight</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>39156-5</td>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>6299-2</td>\n",
       "      <td>Urea Nitrogen</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2339-0</td>\n",
       "      <td>Glucose</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>6298-4</td>\n",
       "      <td>Potassium</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2947-0</td>\n",
       "      <td>Sodium</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2069-3</td>\n",
       "      <td>Chloride</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             system     code                                   display  count\n",
       "0  http://loinc.org   4548-4  Hemoglobin A1c/Hemoglobin.total in Blood   1753\n",
       "1  http://loinc.org   8302-2                               Body Height   1377\n",
       "2  http://loinc.org  55284-4                            Blood Pressure   1377\n",
       "3  http://loinc.org  29463-7                               Body Weight   1377\n",
       "4  http://loinc.org  39156-5                           Body Mass Index   1350\n",
       "5  http://loinc.org   6299-2                             Urea Nitrogen    871\n",
       "6  http://loinc.org   2339-0                                   Glucose    871\n",
       "7  http://loinc.org   6298-4                                 Potassium    871\n",
       "8  http://loinc.org   2947-0                                    Sodium    871\n",
       "9  http://loinc.org   2069-3                                  Chloride    871"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.groupBy('system', 'code', 'display') \\\n",
    "     .count() \\\n",
    "     .orderBy('count', ascending=False) \\\n",
    "     .limit(10) \\\n",
    "     .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing resources to a database\n",
    "Directly loading JSON or XML FHIR bundles is useful for ingesting and early exploration of data, but a more efficient format works better repeated use. Since Bunsen encodes resources natively in Apache Spark dataframes, we can take advantage of Spark's ability to write it to a Hive database. Bunsen offers the *write_to_database* function as a convenient way to write resources from bundles to a database, with a table for each resource. \n",
    "\n",
    "Note that each table preserves the original, nested structure definition of the FHIR resource, and is field-for-field equivalent. \n",
    "\n",
    "The cell below will save our test data to tables in the \"tutorial_small\" database. When running it, you can see progress in the Spark UI at http://localhost:4040.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = ['allergyintolerance',\n",
    "             'careplan',\n",
    "             'claim',\n",
    "             'condition',\n",
    "             'encounter',\n",
    "             'immunization',\n",
    "             'medication',\n",
    "             'medicationrequest',\n",
    "             'observation',\n",
    "             'organization',\n",
    "             'patient',\n",
    "             'procedure']\n",
    "\n",
    "write_to_database(spark, \n",
    "                  bundles, \n",
    "                  'tutorial_small',\n",
    "                  resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from a Hive database\n",
    "Now that we've saved our data to a Hive database, we can easily view and query the tables with Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>allergyintolerance</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>careplan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>claim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>condition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>encounter</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>immunization</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>medication</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>medicationrequest</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>observation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>organization</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>patient</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tutorial_small</td>\n",
       "      <td>procedure</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          database           tableName  isTemporary\n",
       "0   tutorial_small  allergyintolerance        False\n",
       "1   tutorial_small            careplan        False\n",
       "2   tutorial_small               claim        False\n",
       "3   tutorial_small           condition        False\n",
       "4   tutorial_small           encounter        False\n",
       "5   tutorial_small        immunization        False\n",
       "6   tutorial_small          medication        False\n",
       "7   tutorial_small   medicationrequest        False\n",
       "8   tutorial_small         observation        False\n",
       "9   tutorial_small        organization        False\n",
       "10  tutorial_small             patient        False\n",
       "11  tutorial_small           procedure        False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use tutorial_small')\n",
    "spark.sql('show tables').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:e538491e-cf8e-4a3f-97a5-45811e066f27</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:dcad3c44-64de-43b6-b24c-989f8f27c71d</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:5804a9d3-3518-4862-a1e4-a61b0f1a4be4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:2bf9eab0-fec0-41b2-9f91-3369e38b98f6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:90a7ded5-a5ce-43df-b973-7bc7ce7a3011</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:8f538e46-a1d1-4c75-beb7-e3946124e730</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:6f58dbea-7532-4090-97a8-79982bab98f5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:aa251e83-9a9b-446f-ba2f-87e2da7c4d34</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:73bbd5a3-00b5-4216-bd5d-601359ca9e42</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reference  cnt\n",
       "0  urn:uuid:e206880c-7762-4aee-a3e2-5a8c89512c18   53\n",
       "1  urn:uuid:e538491e-cf8e-4a3f-97a5-45811e066f27   44\n",
       "2  urn:uuid:dcad3c44-64de-43b6-b24c-989f8f27c71d   33\n",
       "3  urn:uuid:5804a9d3-3518-4862-a1e4-a61b0f1a4be4   31\n",
       "4  urn:uuid:2bf9eab0-fec0-41b2-9f91-3369e38b98f6   19\n",
       "5  urn:uuid:90a7ded5-a5ce-43df-b973-7bc7ce7a3011   18\n",
       "6  urn:uuid:8f538e46-a1d1-4c75-beb7-e3946124e730   16\n",
       "7  urn:uuid:6f58dbea-7532-4090-97a8-79982bab98f5   12\n",
       "8  urn:uuid:aa251e83-9a9b-446f-ba2f-87e2da7c4d34    8\n",
       "9  urn:uuid:73bbd5a3-00b5-4216-bd5d-601359ca9e42    6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select subject.reference, \n",
    "       count(*) cnt\n",
    "from encounter\n",
    "where class.code != 'WELLNESS' and\n",
    "      period.start > '2013'\n",
    "group by subject.reference\n",
    "order by cnt desc\n",
    "limit 10\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Valuesets\n",
    "Bunsen has built-in support for working with FHIR valuesets. As a convenience, the APIs in the bunsen.stu3.codes package offers ways to save valuesets to Hive tables that are more easily used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [database, tableName, isTemporary]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the value sets and save them to an ontologies database for easy future use\n",
    "spark.sql('create database IF NOT EXISTS tutorial_ontologies')\n",
    "spark.sql('use tutorial_ontologies')\n",
    "spark.sql('show tables').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bunsen.stu3.codes import create_value_sets\n",
    "# Drop table: valuesets if exist\n",
    "spark.sql('create database IF NOT EXISTS tutorial_ontologies')\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS tutorial_ontologies.valuesets\");\n",
    "# Drop table: values if exist\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS tutorial_ontologies.values\");\n",
    "# Load the valuesets from bundles\n",
    "valueset_bundles = load_from_directory(spark, 'gs://bunsen/data/valuesets')\n",
    "valueset_data = extract_entry(spark, valueset_bundles, 'valueset')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o276.writeToDatabase.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:224)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:154)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:322)\n\tat org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:308)\n\tat com.cerner.bunsen.codes.base.AbstractValueSets.writeToTables(AbstractValueSets.java:523)\n\tat com.cerner.bunsen.codes.base.AbstractValueSets.writeToDatabase(AbstractValueSets.java:451)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 69.0 failed 4 times, most recent failure: Lost task 1.3 in stage 69.0 (TID 3667, hive-cluster1-w-1.c.grand-magpie-222719.internal, executor 1): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:285)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: Invalid bucket name (g-warehouse) or object name (hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:96)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getGcsPath(GoogleHadoopFileSystem.java:172)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:762)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:241)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:342)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:302)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.org$apache$spark$sql$execution$datasources$FileFormatWriter$DynamicPartitionWriteTask$$newOutputWriter(FileFormatWriter.scala:511)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:546)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:527)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.execute(FileFormatWriter.scala:527)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:267)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1414)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:272)\n\t... 8 more\nCaused by: java.net.URISyntaxException: Illegal character in path at index 140: gs://g-warehouse/hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet\n\tat java.net.URI$Parser.fail(URI.java:2848)\n\tat java.net.URI$Parser.checkChars(URI.java:3021)\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3105)\n\tat java.net.URI$Parser.parse(URI.java:3053)\n\tat java.net.URI.<init>(URI.java:588)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:91)\n\t... 28 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:194)\n\t... 31 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:285)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: Invalid bucket name (g-warehouse) or object name (hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:96)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getGcsPath(GoogleHadoopFileSystem.java:172)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:762)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:241)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:342)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:302)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.org$apache$spark$sql$execution$datasources$FileFormatWriter$DynamicPartitionWriteTask$$newOutputWriter(FileFormatWriter.scala:511)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:546)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:527)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.execute(FileFormatWriter.scala:527)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:267)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1414)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:272)\n\t... 8 more\nCaused by: java.net.URISyntaxException: Illegal character in path at index 140: gs://g-warehouse/hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet\n\tat java.net.URI$Parser.fail(URI.java:2848)\n\tat java.net.URI$Parser.checkChars(URI.java:3021)\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3105)\n\tat java.net.URI$Parser.parse(URI.java:3053)\n\tat java.net.URI.<init>(URI.java:588)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:91)\n\t... 28 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-27eac62db48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_value_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_value_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueset_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_to_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tutorial_ontologies'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/bunsen/python/bunsen/codes/__init__.py\u001b[0m in \u001b[0;36mwrite_to_database\u001b[0;34m(self, database)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0msets\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvalue_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteToDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHierarchies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o276.writeToDatabase.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:224)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:154)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:322)\n\tat org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:308)\n\tat com.cerner.bunsen.codes.base.AbstractValueSets.writeToTables(AbstractValueSets.java:523)\n\tat com.cerner.bunsen.codes.base.AbstractValueSets.writeToDatabase(AbstractValueSets.java:451)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 69.0 failed 4 times, most recent failure: Lost task 1.3 in stage 69.0 (TID 3667, hive-cluster1-w-1.c.grand-magpie-222719.internal, executor 1): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:285)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: Invalid bucket name (g-warehouse) or object name (hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:96)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getGcsPath(GoogleHadoopFileSystem.java:172)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:762)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:241)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:342)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:302)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.org$apache$spark$sql$execution$datasources$FileFormatWriter$DynamicPartitionWriteTask$$newOutputWriter(FileFormatWriter.scala:511)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:546)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:527)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.execute(FileFormatWriter.scala:527)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:267)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1414)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:272)\n\t... 8 more\nCaused by: java.net.URISyntaxException: Illegal character in path at index 140: gs://g-warehouse/hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet\n\tat java.net.URI$Parser.fail(URI.java:2848)\n\tat java.net.URI$Parser.checkChars(URI.java:3021)\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3105)\n\tat java.net.URI$Parser.parse(URI.java:3053)\n\tat java.net.URI.<init>(URI.java:588)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:91)\n\t... 28 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:194)\n\t... 31 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:285)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: Invalid bucket name (g-warehouse) or object name (hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:96)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getGcsPath(GoogleHadoopFileSystem.java:172)\n\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.create(GoogleHadoopFileSystemBase.java:762)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:241)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:342)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:302)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.org$apache$spark$sql$execution$datasources$FileFormatWriter$DynamicPartitionWriteTask$$newOutputWriter(FileFormatWriter.scala:511)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:546)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask$$anonfun$execute$5.apply(FileFormatWriter.scala:527)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$DynamicPartitionWriteTask.execute(FileFormatWriter.scala:527)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:267)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1414)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:272)\n\t... 8 more\nCaused by: java.net.URISyntaxException: Illegal character in path at index 140: gs://g-warehouse/hadoop/tutorial_ontologies.db/valuesets/_temporary/0/_temporary/attempt_20181126203459_0069_m_000001_3/timestamp=2018-11-26 20%3A34%3A30.458/part-00001-cff111e0-d909-4b9a-9fa6-d23384be381b.c000.snappy.parquet\n\tat java.net.URI$Parser.fail(URI.java:2848)\n\tat java.net.URI$Parser.checkChars(URI.java:3021)\n\tat java.net.URI$Parser.parseHierarchical(URI.java:3105)\n\tat java.net.URI$Parser.parse(URI.java:3053)\n\tat java.net.URI.<init>(URI.java:588)\n\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:91)\n\t... 28 more\n"
     ]
    }
   ],
   "source": [
    "create_value_sets(spark).with_value_sets(valueset_data).write_to_database('tutorial_ontologies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can more easily look at the values in our valuesets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>version</th>\n",
       "      <th>value</th>\n",
       "      <th>valueseturi</th>\n",
       "      <th>valuesetversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>20180301</td>\n",
       "      <td>15777000</td>\n",
       "      <td>http://engineering.cerner.com/bunsen/example</td>\n",
       "      <td>201806001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>20180301</td>\n",
       "      <td>44054006</td>\n",
       "      <td>http://engineering.cerner.com/bunsen/example</td>\n",
       "      <td>201806001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>20180301</td>\n",
       "      <td>15777000</td>\n",
       "      <td>http://engineering.cerner.com/bunsen/example</td>\n",
       "      <td>201806001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>20180301</td>\n",
       "      <td>44054006</td>\n",
       "      <td>http://engineering.cerner.com/bunsen/example</td>\n",
       "      <td>201806001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>14647-2</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2093-3</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>35200-5</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>9342-7</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>14647-2</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2093-3</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>35200-5</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://loinc.org</td>\n",
       "      <td>2.36</td>\n",
       "      <td>9342-7</td>\n",
       "      <td>http://hl7.org/fhir/ValueSet/example-extensional</td>\n",
       "      <td>20150622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    system   version     value  \\\n",
       "0   http://snomed.info/sct  20180301  15777000   \n",
       "1   http://snomed.info/sct  20180301  44054006   \n",
       "2   http://snomed.info/sct  20180301  15777000   \n",
       "3   http://snomed.info/sct  20180301  44054006   \n",
       "4         http://loinc.org      2.36   14647-2   \n",
       "5         http://loinc.org      2.36    2093-3   \n",
       "6         http://loinc.org      2.36   35200-5   \n",
       "7         http://loinc.org      2.36    9342-7   \n",
       "8         http://loinc.org      2.36   14647-2   \n",
       "9         http://loinc.org      2.36    2093-3   \n",
       "10        http://loinc.org      2.36   35200-5   \n",
       "11        http://loinc.org      2.36    9342-7   \n",
       "\n",
       "                                         valueseturi valuesetversion  \n",
       "0       http://engineering.cerner.com/bunsen/example       201806001  \n",
       "1       http://engineering.cerner.com/bunsen/example       201806001  \n",
       "2       http://engineering.cerner.com/bunsen/example       201806001  \n",
       "3       http://engineering.cerner.com/bunsen/example       201806001  \n",
       "4   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "5   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "6   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "7   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "8   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "9   http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "10  http://hl7.org/fhir/ValueSet/example-extensional        20150622  \n",
       "11  http://hl7.org/fhir/ValueSet/example-extensional        20150622  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('tutorial_ontologies.values').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>implicitRules</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>identifier</th>\n",
       "      <th>version</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>description</th>\n",
       "      <th>useContext</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>immutable</th>\n",
       "      <th>purpose</th>\n",
       "      <th>copyright</th>\n",
       "      <th>extensible</th>\n",
       "      <th>compose</th>\n",
       "      <th>expansion</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, meta, implicitRules, language, text, url, identifier, version, name, title, status, experimental, date, publisher, contact, description, useContext, jurisdiction, immutable, purpose, copyright, extensible, compose, expansion, timestamp]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('tutorial_ontologies.valuesets').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Valuesets\n",
    "Finally, we illustrate how we can easily use FHIR valuesets within Spark SQL. Bunsen provides an *in_valueset* user-defined function that can be invoked directly from SQL, so users can easily work with valuesets without needing complex joins to separate ontology tables.\n",
    "\n",
    "First, we will push some interesting valuesets to the cluster with the *push_valuesets* function seen below. This uses Apache Spark's broadcast variables to get this reference data on each node, so it can be easily used. Details are in that function documentation, but typically users work with valuesets in one of three ways:\n",
    "\n",
    "* From a FHIR ValueSet resource, as illustrated here\n",
    "* As a collection of values in a Python structure\n",
    "* As an is-a relationship in some ontology, like LOINC or SNOMED.\n",
    "\n",
    "Further documentation can be viewed in the function documentation or via help(push_valuesets).\n",
    "\n",
    "Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bunsen.stu3.valuesets import push_valuesets, valueset\n",
    "\n",
    "# Push multiple valuesets for this example, even though we use only one.\n",
    "push_valuesets(spark, \n",
    "               {'ldl'               : [('http://loinc.org', '18262-6')],                \n",
    "                'hdl'               : [('http://loinc.org', '2085-9')],\n",
    "                'cholesterol'       : valueset('http://hl7.org/fhir/ValueSet/example-extensional', '20150622')},\n",
    "               database='tutorial_ontologies'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>242.6102</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>246.6088</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>252.2379</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>257.2211</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>251.0915</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>252.0646</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>256.5613</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>251.2045</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>246.4793</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45</td>\n",
       "      <td>244.7487</td>\n",
       "      <td>mg/dL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reference     value   unit\n",
       "0  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  242.6102  mg/dL\n",
       "1  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  246.6088  mg/dL\n",
       "2  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  252.2379  mg/dL\n",
       "3  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  257.2211  mg/dL\n",
       "4  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  251.0915  mg/dL\n",
       "5  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  252.0646  mg/dL\n",
       "6  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  256.5613  mg/dL\n",
       "7  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  251.2045  mg/dL\n",
       "8  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  246.4793  mg/dL\n",
       "9  urn:uuid:710a77bd-57f8-401e-a149-a686ce193e45  244.7487  mg/dL"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select subject.reference, \n",
    "       valueQuantity.value,\n",
    "       valueQuantity.unit\n",
    "from tutorial_small.observation\n",
    "where in_valueset(code, 'cholesterol')\n",
    "limit 10\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
